{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization\n",
    "\n",
    "Implementation of different normalization methods for the annotated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "- anndata: 0.10.7\n",
    "- numpy: 1.26.4\n",
    "- scipy: 1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/adata_1000x1000_sample.h5ad\"\n",
    "# file_path = \"/home/ubuntu/projects/project_data/thesis/global_raw.h5ad\"\n",
    "\n",
    "adata = ad.read_h5ad(filename=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts per Million (CPM)\n",
    "\n",
    "CPM normalization is performed by dividing the mapped reads count by a per million scaling factor of total mapped reads [[1]](https://www.reneshbedre.com/blog/expression_units.html).  \n",
    "In scRNA-seq we want to compare different cells with each other, therefor the caclulation compared to normal RNA-seq is a bit different. The formula looks like this:\n",
    "$$CPM_{ij} = \\frac{count\\ gene\\ j * 10^6}{\\sum{counts\\ cell\\ i}}$$  \n",
    "\n",
    "**Note:** Gene length is not considered during normalization. For this analysis gene length seems not important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cpm(count_matrix):\n",
    "    # Sums over all rows (cells) to get total counts\n",
    "    cell_counts = np.sum(count_matrix, axis=1)\n",
    "\n",
    "    # Caclualte the CPM normalized values\n",
    "    cpm_matrix = count_matrix * 1e6 / cell_counts[:, np.newaxis]\n",
    "\n",
    "    return cpm_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[250000.        ,      0.        , 750000.        ],\n",
       "       [166666.66666667,      0.        , 833333.33333333],\n",
       "       [800000.        ,      0.        , 200000.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_matrix = np.array([[10, 0, 30],\n",
    "                           [5, 0, 25],\n",
    "                           [20, 0, 5]])\n",
    "\n",
    "example_result = calculate_cpm(example_matrix)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected result after running:  \n",
    "```python\n",
    "array([[250000.        ,      0.        , 750000.        ],\n",
    "       [166666.66666667,      0.        , 833333.33333333],\n",
    "       [800000.        ,      0.        , 200000.        ]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implement the divisions of values for the sparse matrix, a diagonal matrix of the reciprocals of the row sums was created. By multiplying this diagonal matrix, the division of the values could be emulated [[2]](https://stackoverflow.com/questions/42225269/scipy-sparse-matrix-division)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x1000 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 39019 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_counts = adata.X.copy()\n",
    "adata_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sparse_cpm(count_matrix):\n",
    "    # Calcualte diag matrix as metioned above\n",
    "    cell_counts = sp.diags(1 / count_matrix.sum(axis=1).A.ravel())\n",
    "    # Calcualte numerator for formula\n",
    "    multplied_counts = count_matrix.dot(1e6)\n",
    "\n",
    "    # Calcualte CPM values\n",
    "    cpm_matrix = cell_counts.dot(multplied_counts)\n",
    "\n",
    "    return cpm_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x1000 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 39019 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpm_normalized = calculate_sparse_cpm(adata_counts)\n",
    "cpm_normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-0-Max-1 Normalization\n",
    "\n",
    "Min-Max normalization is a normalization typically used in machine learning.  \n",
    "With this normalization method the values are normalized so that the lowest value in the dataset is the **min** value and the highest value is **max** [[3]](https://www.datacamp.com/tutorial/normalization-in-machine-learning).  \n",
    "The formula for this methods looks like this:  \n",
    "$$X_{normalized} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$  \n",
    "\n",
    "**Note:** This functionality is also implemented in the Python library *sklearn*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_min_max(data, min_val=0, max_val=1):\n",
    "    min_data = np.min(data)\n",
    "    max_data = np.max(data)\n",
    "\n",
    "    # If min and max are not set to 0 and 1 this is the full formula\n",
    "    min_max_normalized = (data - min_data) / (max_data - min_data) * (max_val - min_val) + min_val\n",
    "\n",
    "    return min_max_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[250000.              0.         750000.        ]\n",
      " [166666.66666667      0.         833333.33333333]\n",
      " [800000.              0.         200000.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3 , 0.  , 0.9 ],\n",
       "       [0.2 , 0.  , 1.  ],\n",
       "       [0.96, 0.  , 0.24]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_matrix = example_result\n",
    "print(example_matrix)\n",
    "\n",
    "example_result_2 = calculate_min_max(example_matrix)\n",
    "example_result_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Min-Max method has extra calculations. These are added in this function to provide full functionality if the min and max values are **not 0 and 1**. If this is not the case, the steps are not needed. If the boundaries for the data **are 0 and 1**:  \n",
    "$$bound_{max} - bound_{min}$$ \n",
    "- Turns out to 1 - 0 = 1 (result multiplied with 1)\n",
    "$$bound_{min}$$\n",
    "- Turns out to 0 (adds 0 to result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caclulate_sparse_min_max(data, min_val=0, max_val=1):\n",
    "    # Get min value from sparse matrix\n",
    "    min_data = data.min()\n",
    "    # Get max value from sparse matrix\n",
    "    max_data = data.max()\n",
    "\n",
    "    # Calculate Min-Max as described above\n",
    "    min_max_matrix = (cpm_normalized - min_data) / (max_data - min_data) * (max_val - min_val) + min_val\n",
    "\n",
    "    return min_max_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 39019 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_normalized = caclulate_sparse_min_max(cpm_normalized)\n",
    "min_max_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Save the results as additional layers in the anndata object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers[\"cpm_normalized\"] = cpm_normalized\n",
    "adata.layers[\"min_max_normalized\"] = min_max_normalized\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad(filename=\"../data/adata_normalized_sample.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder\n",
    "\n",
    "This notebook demonstrates the workflow for building and training a Variational Autoencoder (VAE) using PyTorch with the MNIST dataset. This notebook will walk through the key steps, including data preparation, model definition, training, and evaluation, providing a comprehensive guide to implementing VAEs for unsupervised learning tasks on handwritten digit images.\n",
    "> Generated by ChatGPT\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries\n",
    "\n",
    "Library | Version | Channel\n",
    "--- | --- | ---\n",
    "NumPy | 1.26.4 | default\n",
    "PyTorch | 2.2.2 | pytorch\n",
    "Torchvision | 0.17.2 | pytorch\n",
    "Tensorboard | / | conda-forge\n",
    "tqdm | / | conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in libraries\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "# Third-party libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 128  # Power of 2 is optimized in many libraries\n",
    "\n",
    "# Model architecture\n",
    "size_input = 784\n",
    "size_hidden = 512\n",
    "size_latent = 2\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-2\n",
    "\n",
    "# Training\n",
    "num_epochs = 50\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device Specification\n",
    "\n",
    "The CUDA architecture from NVIDIA enables high-performance parallel computing on GPUs, optimizing tasks through concurrent execution and accelerating applications like deep learning and scientific simulations.\n",
    "> Generated by ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Established the type of device used for model processing\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cuda = True if device == \"cuda\" else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "The [MNIST](http://yann.lecun.com/exdb/mnist/) dataset is a widely-used benchmark in machine learning, consisting of 70,000 images of handwritten digits from 0 to 9. Each image is a 28x28 grayscale pixel grid. Due to its simplicity and well-structured format, MNIST serves as an excellent starting point for developing and testing machine learning models, particularly in the field of image recognition and classification\n",
    "> Generated by ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "\n",
    "For the model to be able to process the MNIST data, the data has to be transformed into a format that is understandable for our model. The following steps are applied to the data:\n",
    "\n",
    "1. `v2.ToImage()` - Converts the tensor to an image format\n",
    "2. `v2.toDtype()` - Converts the img to a floating point tensor\n",
    "3. `v2.Lambda()` - Zero centers (normalization) the data and flattens it afterward for 1-dimensional input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),  # Converts tensor to img\n",
    "        v2.ToDtype(torch.float32, scale=True),  # Converts img to float tensor\n",
    "        v2.Lambda(lambda x: x.view(-1) - 0.5),  # Zero centers and flattens\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split\n",
    "\n",
    "In deep learning, data splitting involves dividing the dataset into distinct subsets: typically training, validation, and test sets. This approach ensures that the model is trained on one subset, validated on another to tune hyperparameters, and finally evaluated on a separate set to assess its performance and generalization capability.\n",
    "> Generated by ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the training data\n",
    "train_data = datasets.MNIST(\n",
    "    \"~/.pytorch/MNIST_data/\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=img_transform,\n",
    ")\n",
    "\n",
    "## No seperate validation step\n",
    "\n",
    "# Download and load the test data\n",
    "test_data = datasets.MNIST(\n",
    "    \"~/.pytorch/MNIST_data/\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=img_transform,\n",
    ")\n",
    "\n",
    "## Create data loaders\n",
    "## Used to iterate over dataset\n",
    "\n",
    "# Training data loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  # Shuffle to reduce batch effect\n",
    ")\n",
    "\n",
    "# Test data loader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /home/ubuntu/.pytorch/MNIST_data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "                 ToImage()\n",
       "                 ToDtype(scale=True)\n",
       "                 Lambda(<lambda>, types=['object'])\n",
       "           )"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: /home/ubuntu/.pytorch/MNIST_data/\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "                 ToImage()\n",
       "                 ToDtype(scale=True)\n",
       "                 Lambda(<lambda>, types=['object'])\n",
       "           )"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset"
   ]
  },
  {
   "attachments": {
    "Basic-structure-of-Variational-Autoencoder-VAE-3661557727.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "The **Variational Autoencoder (VAE)** was firstly introduced by Kingma and Welling in 2013 [[1]](https://arxiv.org/abs/1312.6114). A VAE is a generative model comprising an **encoder**, which maps the input data to a latent space. This component is also referred to as a recognition model, as it is responsible for recognising important patterns within the data. The other component of the model is a **decoder**, which generates a reconstructed representation of the input data. This is why the decoder is also referred to as the generative model [[2]](https://hunterheidenreich.com/posts/modern-variational-autoencoder-in-pytorch/).\n",
    "\n",
    "![Basic-structure-of-Variational-Autoencoder-VAE-3661557727.png](attachment:Basic-structure-of-Variational-Autoencoder-VAE-3661557727.png)  \n",
    "[Source](https://jiki.cs.ui.ac.id/index.php/jiki/article/view/761)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VAEOutput:\n",
    "    \"\"\"\n",
    "    Dataclass for Variational Autoencoder (VAE) output.\n",
    "\n",
    "    Attributes:\n",
    "        z_dist (torch.distributions.Distribution): The distribution of the latent variable z.\n",
    "        z_sample (torch.Tensor): The sampled value of the latent variable z.\n",
    "        x_recon (torch.Tensor): The reconstructed output from the VAE.\n",
    "        loss (torch.Tensor): The overall loss of the VAE.\n",
    "        loss_recon (torch.Tensor): The reconstruction loss component of the VAE loss.\n",
    "        loss_kl (torch.Tensor): The KL divergence component of the VAE loss.\n",
    "    \"\"\"\n",
    "\n",
    "    z_dist: torch.distributions.Distribution\n",
    "    z_sample: torch.Tensor\n",
    "    x_recon: torch.Tensor\n",
    "    loss: torch.Tensor\n",
    "    loss_recon: torch.Tensor\n",
    "    loss_kl: torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder (AE) class.\n",
    "\n",
    "    Args:\n",
    "        size_input (int): Dimensionality of the input data.\n",
    "        size_hidden (int): Dimensionality of the hidden layer.\n",
    "        size_latent (int): Dimensionality of the latent space\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size_input: int, size_hidden: int, size_latent: int):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(size_input, size_hidden),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(size_hidden, size_hidden // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(size_hidden // 2, size_hidden // 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(size_hidden // 4, size_hidden // 8),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(size_hidden // 8, 2 * size_latent),  # For mean and variance\n",
    "        )\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(size_latent, size_hidden // 8),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(size_hidden // 8, size_hidden // 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(size_hidden // 4, size_hidden // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(size_hidden // 2, size_hidden),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(size_hidden, size_input),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        # Set model to device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def encode(self, x, eps: float = 1e-8):\n",
    "        \"\"\"\n",
    "        Encodes the input data into the latent space.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            eps (float): Small value to avoid numerical instability.\n",
    "\n",
    "        Returns:\n",
    "            torch.distributions.MultivariateNormal: Normal distribution of the encoded data.\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)\n",
    "        mu, logvar = torch.chunk(x, 2, dim=-1)\n",
    "        scale = self.softplus(logvar) + eps\n",
    "        scale_tril = torch.diag_embed(scale)\n",
    "\n",
    "        return torch.distributions.MultivariateNormal(mu, scale_tril=scale_tril)\n",
    "\n",
    "    def reparameterize(self, dist):\n",
    "        \"\"\"\n",
    "        Reparameterizes the encoded data to sample from the latent space.\n",
    "\n",
    "        Args:\n",
    "            dist (torch.distributions.MultivariateNormal): Normal distribution of the encoded data.\n",
    "        Returns:\n",
    "            torch.Tensor: Sampled data from the latent space.\n",
    "        \"\"\"\n",
    "        return dist.rsample()\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decodes the data from the latent space to the original input space.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): Data in the latent space.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed data in the original input space.\n",
    "        \"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x, compute_loss: bool = True):\n",
    "        \"\"\"\n",
    "        Performs a forward pass of the VAE.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            compute_loss (bool): Whether to compute the loss or not.\n",
    "\n",
    "        Returns:\n",
    "            VAEOutput: VAE output dataclass.\n",
    "        \"\"\"\n",
    "        dist = self.encode(x)\n",
    "        z = self.reparameterize(dist)\n",
    "        recon_x = self.decode(z)\n",
    "\n",
    "        if not compute_loss:\n",
    "            return VAEOutput(\n",
    "                z_dist=dist,\n",
    "                z_sample=z,\n",
    "                x_recon=recon_x,\n",
    "                loss=None,\n",
    "                loss_recon=None,\n",
    "                loss_kl=None,\n",
    "            )\n",
    "\n",
    "        # compute loss terms\n",
    "        loss_recon = (\n",
    "            F.binary_cross_entropy(recon_x, x + 0.5, reduction=\"none\").sum(-1).mean()\n",
    "        )\n",
    "        std_normal = torch.distributions.MultivariateNormal(\n",
    "            torch.zeros_like(z, device=z.device),\n",
    "            scale_tril=torch.eye(z.shape[-1], device=z.device)\n",
    "            .unsqueeze(0)\n",
    "            .expand(z.shape[0], -1, -1),\n",
    "        )\n",
    "        loss_kl = torch.distributions.kl.kl_divergence(dist, std_normal).mean()\n",
    "\n",
    "        loss = loss_recon + loss_kl\n",
    "\n",
    "        return VAEOutput(\n",
    "            z_dist=dist,\n",
    "            z_sample=z,\n",
    "            x_recon=recon_x,\n",
    "            loss=loss,\n",
    "            loss_recon=loss_recon,\n",
    "            loss_kl=loss_kl,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VariationalAutoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (3): SiLU()\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): SiLU()\n",
       "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (7): SiLU()\n",
       "    (8): Linear(in_features=64, out_features=4, bias=True)\n",
       "  )\n",
       "  (softplus): Softplus(beta=1, threshold=20)\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (3): SiLU()\n",
       "    (4): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (5): SiLU()\n",
       "    (6): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (7): SiLU()\n",
       "    (8): Linear(in_features=512, out_features=784, bias=True)\n",
       "    (9): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VariationalAutoencoder(size_input, size_hidden, size_latent)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Training models with PyTorch involves the process of optimizing neural networks to learn patterns and make predictions from data. PyTorch, known for its dynamic computational graph and flexible architecture, facilitates efficient model training through features like automatic differentiation and GPU acceleration, enabling researchers and developers to implement and iterate on complex machine learning algorithms effectively.\n",
    "> Generated with ChatGPT\n",
    "\n",
    "Typical training loop:\n",
    "\n",
    "- Iterating over mini-batches of data\n",
    "- Forward Pass: Computing model predictions on input data\n",
    "- Calculating Loss: Using the loss function to measure the discrepancy between predictions and ground truth\n",
    "- Backward Pass: Computing gradients of the loss with respect to model parameters\n",
    "- Optimizer Step: Updating model parameters using the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, prev_updates, device, writer=None):\n",
    "    \"\"\"\n",
    "    Trains the model on the given data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        dataloader (torch.utils.data.DataLoader): The data loader.\n",
    "        optimizer (torch.optim.Optim): The optimizer.\n",
    "        prev_updates (int): Number of previous updates.\n",
    "        device (str): Device.\n",
    "        writer: The TensorBoard writer.\n",
    "    \"\"\"\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(dataloader)):\n",
    "        n_upd = prev_updates + batch_idx\n",
    "\n",
    "        data = data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        output = model(data)  # Forward pass\n",
    "        loss = output.loss\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if n_upd % 100 == 0:\n",
    "            # Calculate and log gradient norms\n",
    "            total_norm = 0.0\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    param_norm = p.grad.data.norm(2)\n",
    "                    total_norm += param_norm.item() ** 2\n",
    "            total_norm = total_norm ** (1.0 / 2)\n",
    "\n",
    "            print(\n",
    "                f\"Step {n_upd:,} (N samples: {n_upd*batch_size:,}), Loss: {loss.item():.4f} (Recon: {output.loss_recon.item():.4f}, KL: {output.loss_kl.item():.4f}) Grad: {total_norm:.4f}\"\n",
    "            )\n",
    "\n",
    "            if writer is not None:\n",
    "                global_step = n_upd\n",
    "                writer.add_scalar(\"Loss/Train\", loss.item(), global_step)\n",
    "                writer.add_scalar(\n",
    "                    \"Loss/Train/BCE\", output.loss_recon.item(), global_step\n",
    "                )\n",
    "                writer.add_scalar(\"Loss/Train/KLD\", output.loss_kl.item(), global_step)\n",
    "                writer.add_scalar(\"GradNorm/Train\", total_norm, global_step)\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()  # Update the model parameters\n",
    "\n",
    "    return prev_updates + len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, cur_step, latent_dim, writer=None):\n",
    "    \"\"\"\n",
    "    Tests the model on the given data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to test.\n",
    "        dataloader (torch.utils.data.DataLoader): The data loader.\n",
    "        cur_step (int): The current step.\n",
    "        writer: The TensorBoard writer.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    test_recon_loss = 0\n",
    "    test_kl_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, _ in tqdm(dataloader, desc=\"Testing\"):\n",
    "            data = data.to(device)\n",
    "            data = data.view(data.size(0), -1)  # Flatten the data\n",
    "\n",
    "            output = model(data, compute_loss=True)  # Forward pass\n",
    "\n",
    "            test_loss += output.loss.item()\n",
    "            test_recon_loss += output.loss_recon.item()\n",
    "            test_kl_loss += output.loss_kl.item()\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    test_recon_loss /= len(dataloader)\n",
    "    test_kl_loss /= len(dataloader)\n",
    "    print(\n",
    "        f\"====> Test set loss: {test_loss:.4f} (BCE: {test_recon_loss:.4f}, KLD: {test_kl_loss:.4f})\"\n",
    "    )\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.add_scalar(\"Loss/Test\", test_loss, global_step=cur_step)\n",
    "        writer.add_scalar(\n",
    "            \"Loss/Test/BCE\", output.loss_recon.item(), global_step=cur_step\n",
    "        )\n",
    "        writer.add_scalar(\"Loss/Test/KLD\", output.loss_kl.item(), global_step=cur_step)\n",
    "\n",
    "        # Log reconstructions\n",
    "        writer.add_images(\n",
    "            \"Test/Reconstructions\",\n",
    "            output.x_recon.view(-1, 1, 28, 28),\n",
    "            global_step=cur_step,\n",
    "        )\n",
    "        writer.add_images(\n",
    "            \"Test/Originals\", data.view(-1, 1, 28, 28), global_step=cur_step\n",
    "        )\n",
    "\n",
    "        # Log random samples from the latent space\n",
    "        z = torch.randn(16, latent_dim).to(device)\n",
    "        samples = model.decode(z)\n",
    "        writer.add_images(\n",
    "            \"Test/Samples\", samples.view(-1, 1, 28, 28), global_step=cur_step\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/469 [00:00<00:29, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 (N samples: 0), Loss: 543.8928 (Recon: 543.6832, KL: 0.2095) Grad: 13.0905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 106/469 [00:03<00:10, 34.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 (N samples: 12,800), Loss: 205.6424 (Recon: 205.4945, KL: 0.1478) Grad: 26.4306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 206/469 [00:06<00:08, 32.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 (N samples: 25,600), Loss: 212.6903 (Recon: 212.5530, KL: 0.1374) Grad: 39.5371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 306/469 [00:09<00:05, 31.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 (N samples: 38,400), Loss: 207.3431 (Recon: 207.2239, KL: 0.1192) Grad: 29.1476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 406/469 [00:12<00:01, 33.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 (N samples: 51,200), Loss: 207.8585 (Recon: 207.7549, KL: 0.1036) Grad: 31.5077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:14<00:00, 32.54it/s]\n",
      "Testing: 100%|| 79/79 [00:01<00:00, 47.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.9553 (BCE: 206.8634, KLD: 0.0919)\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 34/469 [00:02<00:33, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 (N samples: 64,000), Loss: 203.7049 (Recon: 203.6183, KL: 0.0866) Grad: 26.4945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 135/469 [00:09<00:19, 17.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 (N samples: 76,800), Loss: 213.7066 (Recon: 213.6353, KL: 0.0713) Grad: 36.5362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 235/469 [00:13<00:08, 28.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 700 (N samples: 89,600), Loss: 208.4913 (Recon: 208.4309, KL: 0.0604) Grad: 26.9094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 335/469 [00:17<00:06, 21.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800 (N samples: 102,400), Loss: 204.4975 (Recon: 204.4475, KL: 0.0499) Grad: 29.1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 435/469 [00:22<00:01, 22.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 900 (N samples: 115,200), Loss: 210.3502 (Recon: 210.3090, KL: 0.0412) Grad: 34.4621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.68it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.5924 (BCE: 206.5543, KLD: 0.0381)\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 66/469 [00:02<00:14, 27.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,000 (N samples: 128,000), Loss: 203.3575 (Recon: 203.3227, KL: 0.0348) Grad: 27.6779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 168/469 [00:06<00:10, 27.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,100 (N samples: 140,800), Loss: 209.2319 (Recon: 209.2019, KL: 0.0300) Grad: 29.9103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 268/469 [00:09<00:07, 28.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,200 (N samples: 153,600), Loss: 204.6167 (Recon: 204.5910, KL: 0.0256) Grad: 25.6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 368/469 [00:13<00:03, 27.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,300 (N samples: 166,400), Loss: 204.3644 (Recon: 204.3412, KL: 0.0232) Grad: 31.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 465/469 [00:17<00:00, 20.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,400 (N samples: 179,200), Loss: 206.7537 (Recon: 206.7321, KL: 0.0216) Grad: 29.5205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:17<00:00, 26.29it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 28.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.7214 (BCE: 206.7001, KLD: 0.0213)\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 97/469 [00:05<00:22, 16.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,500 (N samples: 192,000), Loss: 208.3081 (Recon: 208.2883, KL: 0.0198) Grad: 32.7727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 195/469 [00:13<00:23, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,600 (N samples: 204,800), Loss: 202.0800 (Recon: 202.0609, KL: 0.0191) Grad: 29.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 295/469 [00:22<00:19,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,700 (N samples: 217,600), Loss: 208.0779 (Recon: 208.0594, KL: 0.0185) Grad: 28.1474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 395/469 [00:32<00:07,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,800 (N samples: 230,400), Loss: 203.3851 (Recon: 203.3669, KL: 0.0182) Grad: 29.8261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:41<00:00, 11.38it/s]\n",
      "Testing: 100%|| 79/79 [00:06<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.7339 (BCE: 206.7163, KLD: 0.0175)\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 26/469 [00:03<00:51,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,900 (N samples: 243,200), Loss: 209.4773 (Recon: 209.4596, KL: 0.0177) Grad: 28.9717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 126/469 [00:15<00:40,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,000 (N samples: 256,000), Loss: 216.3128 (Recon: 216.2955, KL: 0.0173) Grad: 36.7891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 226/469 [00:28<00:37,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,100 (N samples: 268,800), Loss: 209.8852 (Recon: 209.8679, KL: 0.0173) Grad: 40.5781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 326/469 [00:42<00:22,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,200 (N samples: 281,600), Loss: 203.1270 (Recon: 203.1096, KL: 0.0174) Grad: 29.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 426/469 [00:55<00:06,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,300 (N samples: 294,400), Loss: 206.7958 (Recon: 206.7787, KL: 0.0171) Grad: 24.2286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [01:02<00:00,  7.55it/s]\n",
      "Testing: 100%|| 79/79 [00:07<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.5369 (BCE: 206.5197, KLD: 0.0172)\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 57/469 [00:08<00:57,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,400 (N samples: 307,200), Loss: 206.0850 (Recon: 206.0677, KL: 0.0173) Grad: 31.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 157/469 [00:22<00:45,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,500 (N samples: 320,000), Loss: 210.5840 (Recon: 210.5666, KL: 0.0174) Grad: 29.6857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 257/469 [00:36<00:30,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,600 (N samples: 332,800), Loss: 211.2655 (Recon: 211.2482, KL: 0.0173) Grad: 31.4418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 357/469 [00:51<00:16,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,700 (N samples: 345,600), Loss: 214.0394 (Recon: 214.0217, KL: 0.0177) Grad: 29.8799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 457/469 [01:05<00:01,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,800 (N samples: 358,400), Loss: 204.8963 (Recon: 204.8786, KL: 0.0177) Grad: 28.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [01:07<00:00,  6.93it/s]\n",
      "Testing: 100%|| 79/79 [00:07<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.4620 (BCE: 206.4444, KLD: 0.0176)\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 88/469 [00:13<00:56,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,900 (N samples: 371,200), Loss: 210.5264 (Recon: 210.5088, KL: 0.0177) Grad: 34.0731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 188/469 [00:28<00:42,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,000 (N samples: 384,000), Loss: 202.3405 (Recon: 202.3223, KL: 0.0182) Grad: 23.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|   | 288/469 [00:43<00:27,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,100 (N samples: 396,800), Loss: 205.5794 (Recon: 205.5610, KL: 0.0184) Grad: 27.1870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 388/469 [00:59<00:13,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,200 (N samples: 409,600), Loss: 205.3841 (Recon: 205.3666, KL: 0.0175) Grad: 25.1427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [01:11<00:00,  6.54it/s]\n",
      "Testing: 100%|| 79/79 [00:07<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.4793 (BCE: 206.4618, KLD: 0.0175)\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 19/469 [00:03<01:13,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,300 (N samples: 422,400), Loss: 203.6016 (Recon: 203.5839, KL: 0.0177) Grad: 29.5805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 118/469 [00:19<00:55,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,400 (N samples: 435,200), Loss: 207.3019 (Recon: 207.2839, KL: 0.0180) Grad: 30.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 219/469 [00:35<00:41,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,500 (N samples: 448,000), Loss: 210.7038 (Recon: 210.6855, KL: 0.0183) Grad: 26.5705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 319/469 [00:52<00:26,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,600 (N samples: 460,800), Loss: 212.7276 (Recon: 212.7094, KL: 0.0183) Grad: 24.9115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 418/469 [01:13<00:10,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,700 (N samples: 473,600), Loss: 203.9965 (Recon: 203.9786, KL: 0.0179) Grad: 29.0518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [01:26<00:00,  5.45it/s]\n",
      "Testing: 100%|| 79/79 [00:10<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.3643 (BCE: 206.3461, KLD: 0.0182)\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 49/469 [00:13<01:54,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,800 (N samples: 486,400), Loss: 205.8978 (Recon: 205.8795, KL: 0.0182) Grad: 36.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 148/469 [00:41<02:28,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,900 (N samples: 499,200), Loss: 209.0064 (Recon: 208.9883, KL: 0.0182) Grad: 31.3233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 249/469 [01:24<01:52,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,000 (N samples: 512,000), Loss: 206.8130 (Recon: 206.7948, KL: 0.0181) Grad: 31.9599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 349/469 [02:00<00:37,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,100 (N samples: 524,800), Loss: 202.5812 (Recon: 202.5632, KL: 0.0180) Grad: 26.5115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 449/469 [02:37<00:05,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,200 (N samples: 537,600), Loss: 203.7592 (Recon: 203.7413, KL: 0.0179) Grad: 30.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [02:42<00:00,  2.88it/s]\n",
      "Testing: 100%|| 79/79 [00:10<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.5618 (BCE: 206.5439, KLD: 0.0180)\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 80/469 [00:22<01:50,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,300 (N samples: 550,400), Loss: 207.6062 (Recon: 207.5880, KL: 0.0183) Grad: 30.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 180/469 [00:53<01:23,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,400 (N samples: 563,200), Loss: 207.4047 (Recon: 207.3863, KL: 0.0183) Grad: 28.1122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 280/469 [01:20<00:44,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,500 (N samples: 576,000), Loss: 212.2191 (Recon: 212.2008, KL: 0.0182) Grad: 28.6504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 380/469 [01:43<00:20,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,600 (N samples: 588,800), Loss: 205.2989 (Recon: 205.2803, KL: 0.0187) Grad: 28.8264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [02:03<00:00,  3.79it/s]\n",
      "Testing: 100%|| 79/79 [00:08<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2263 (BCE: 206.2079, KLD: 0.0184)\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 11/469 [00:02<01:46,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,700 (N samples: 601,600), Loss: 212.7418 (Recon: 212.7234, KL: 0.0184) Grad: 31.3890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 111/469 [00:34<01:54,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,800 (N samples: 614,400), Loss: 203.0366 (Recon: 203.0187, KL: 0.0179) Grad: 36.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 211/469 [01:00<00:56,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,900 (N samples: 627,200), Loss: 210.7780 (Recon: 210.7599, KL: 0.0181) Grad: 31.9724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 311/469 [01:19<00:28,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,000 (N samples: 640,000), Loss: 201.9209 (Recon: 201.9025, KL: 0.0184) Grad: 24.9868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 411/469 [01:39<00:10,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,100 (N samples: 652,800), Loss: 204.1772 (Recon: 204.1587, KL: 0.0185) Grad: 31.6779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [01:50<00:00,  4.25it/s]\n",
      "Testing: 100%|| 79/79 [00:06<00:00, 12.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.4281 (BCE: 206.4102, KLD: 0.0178)\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 42/469 [00:08<01:20,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,200 (N samples: 665,600), Loss: 199.5522 (Recon: 199.5325, KL: 0.0197) Grad: 37.2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 143/469 [00:27<01:02,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,300 (N samples: 678,400), Loss: 208.8636 (Recon: 208.8455, KL: 0.0181) Grad: 24.6215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 243/469 [00:46<00:38,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,400 (N samples: 691,200), Loss: 215.2842 (Recon: 215.2661, KL: 0.0181) Grad: 32.1028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 342/469 [01:06<00:26,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,500 (N samples: 704,000), Loss: 210.4953 (Recon: 210.4767, KL: 0.0186) Grad: 28.4385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 443/469 [01:27<00:05,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,600 (N samples: 716,800), Loss: 214.2026 (Recon: 214.1847, KL: 0.0178) Grad: 34.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [01:32<00:00,  5.08it/s]\n",
      "Testing: 100%|| 79/79 [00:06<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2387 (BCE: 206.2205, KLD: 0.0182)\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 74/469 [00:15<01:08,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,700 (N samples: 729,600), Loss: 205.4784 (Recon: 205.4599, KL: 0.0185) Grad: 33.4614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 173/469 [00:37<01:10,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,800 (N samples: 742,400), Loss: 201.7550 (Recon: 201.7364, KL: 0.0186) Grad: 36.2689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 273/469 [01:01<00:50,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,900 (N samples: 755,200), Loss: 207.9773 (Recon: 207.9589, KL: 0.0184) Grad: 26.6366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 374/469 [01:20<00:18,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,000 (N samples: 768,000), Loss: 199.5191 (Recon: 199.5006, KL: 0.0185) Grad: 34.2428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [01:37<00:00,  4.79it/s]\n",
      "Testing: 100%|| 79/79 [00:06<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2883 (BCE: 206.2697, KLD: 0.0186)\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/469 [00:00<01:32,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,100 (N samples: 780,800), Loss: 212.6512 (Recon: 212.6326, KL: 0.0186) Grad: 31.3328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 104/469 [00:19<01:05,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,200 (N samples: 793,600), Loss: 203.9713 (Recon: 203.9517, KL: 0.0196) Grad: 33.6644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 204/469 [00:36<00:47,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,300 (N samples: 806,400), Loss: 201.0150 (Recon: 200.9978, KL: 0.0172) Grad: 33.8346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 304/469 [00:55<00:28,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,400 (N samples: 819,200), Loss: 215.5890 (Recon: 215.5709, KL: 0.0181) Grad: 34.9929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 405/469 [01:11<00:09,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,500 (N samples: 832,000), Loss: 209.2229 (Recon: 209.2045, KL: 0.0184) Grad: 26.1523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [01:21<00:00,  5.77it/s]\n",
      "Testing: 100%|| 79/79 [00:05<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.1045 (BCE: 206.0858, KLD: 0.0188)\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 36/469 [00:05<01:11,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,600 (N samples: 844,800), Loss: 222.0853 (Recon: 222.0664, KL: 0.0190) Grad: 45.8672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 136/469 [00:19<00:44,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,700 (N samples: 857,600), Loss: 208.2233 (Recon: 208.2047, KL: 0.0186) Grad: 31.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 236/469 [00:32<00:29,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,800 (N samples: 870,400), Loss: 204.5374 (Recon: 204.5195, KL: 0.0179) Grad: 34.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 336/469 [00:46<00:16,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,900 (N samples: 883,200), Loss: 207.8862 (Recon: 207.8667, KL: 0.0195) Grad: 37.1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 436/469 [00:59<00:04,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,000 (N samples: 896,000), Loss: 199.6372 (Recon: 199.6190, KL: 0.0181) Grad: 38.5284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [01:03<00:00,  7.34it/s]\n",
      "Testing: 100%|| 79/79 [00:05<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2172 (BCE: 206.1990, KLD: 0.0182)\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 67/469 [00:09<00:50,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,100 (N samples: 908,800), Loss: 203.0557 (Recon: 203.0370, KL: 0.0187) Grad: 30.6531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 167/469 [00:23<00:37,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,200 (N samples: 921,600), Loss: 206.7874 (Recon: 206.7691, KL: 0.0183) Grad: 27.4144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 267/469 [00:36<00:27,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,300 (N samples: 934,400), Loss: 208.6469 (Recon: 208.6279, KL: 0.0191) Grad: 32.3836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 367/469 [00:49<00:12,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,400 (N samples: 947,200), Loss: 213.1025 (Recon: 213.0833, KL: 0.0192) Grad: 35.6072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 467/469 [01:02<00:00,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,500 (N samples: 960,000), Loss: 203.7478 (Recon: 203.7285, KL: 0.0193) Grad: 32.2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [01:03<00:00,  7.42it/s]\n",
      "Testing: 100%|| 79/79 [00:04<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.3980 (BCE: 206.3784, KLD: 0.0195)\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 98/469 [00:12<00:48,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,600 (N samples: 972,800), Loss: 211.3163 (Recon: 211.2976, KL: 0.0187) Grad: 31.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 198/469 [00:24<00:33,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,700 (N samples: 985,600), Loss: 201.7073 (Recon: 201.6883, KL: 0.0189) Grad: 39.7118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 298/469 [00:37<00:24,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,800 (N samples: 998,400), Loss: 206.0033 (Recon: 205.9850, KL: 0.0183) Grad: 28.9344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 398/469 [00:50<00:08,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,900 (N samples: 1,011,200), Loss: 196.5578 (Recon: 196.5403, KL: 0.0176) Grad: 43.5109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:59<00:00,  7.92it/s]\n",
      "Testing: 100%|| 79/79 [00:04<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.3126 (BCE: 206.2929, KLD: 0.0197)\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 28/469 [00:03<00:54,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,000 (N samples: 1,024,000), Loss: 207.2327 (Recon: 207.2138, KL: 0.0190) Grad: 29.4726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 129/469 [00:20<00:41,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,100 (N samples: 1,036,800), Loss: 204.8567 (Recon: 204.8393, KL: 0.0174) Grad: 26.6690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 229/469 [00:32<00:33,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,200 (N samples: 1,049,600), Loss: 209.1959 (Recon: 209.1771, KL: 0.0188) Grad: 24.9209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 329/469 [00:44<00:19,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,300 (N samples: 1,062,400), Loss: 205.8613 (Recon: 205.8425, KL: 0.0188) Grad: 32.9369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 428/469 [10:40<00:03, 11.40it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,400 (N samples: 1,075,200), Loss: 213.9332 (Recon: 213.9156, KL: 0.0176) Grad: 32.9019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [10:44<00:00,  1.37s/it]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 27.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.3868 (BCE: 206.3682, KLD: 0.0186)\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 60/469 [00:04<00:29, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,500 (N samples: 1,088,000), Loss: 203.4437 (Recon: 203.4234, KL: 0.0203) Grad: 28.1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 160/469 [00:11<00:23, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,600 (N samples: 1,100,800), Loss: 207.3161 (Recon: 207.2973, KL: 0.0187) Grad: 32.3561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 260/469 [00:19<00:16, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,700 (N samples: 1,113,600), Loss: 209.5368 (Recon: 209.5188, KL: 0.0180) Grad: 31.8693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 360/469 [00:28<00:09, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,800 (N samples: 1,126,400), Loss: 211.1281 (Recon: 211.1098, KL: 0.0184) Grad: 32.8353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 461/469 [00:36<00:00, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,900 (N samples: 1,139,200), Loss: 209.8360 (Recon: 209.8175, KL: 0.0185) Grad: 33.2062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:36<00:00, 12.80it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 32.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2551 (BCE: 206.2362, KLD: 0.0189)\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 92/469 [00:06<00:27, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,000 (N samples: 1,152,000), Loss: 201.3343 (Recon: 201.3167, KL: 0.0177) Grad: 34.4639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 192/469 [00:13<00:20, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,100 (N samples: 1,164,800), Loss: 202.8355 (Recon: 202.8171, KL: 0.0184) Grad: 29.6405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 292/469 [00:21<00:12, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,200 (N samples: 1,177,600), Loss: 202.7384 (Recon: 202.7196, KL: 0.0188) Grad: 34.5749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 392/469 [00:28<00:05, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,300 (N samples: 1,190,400), Loss: 206.9028 (Recon: 206.8840, KL: 0.0188) Grad: 34.5987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:33<00:00, 13.86it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 32.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2577 (BCE: 206.2382, KLD: 0.0195)\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 22/469 [00:01<00:32, 13.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,400 (N samples: 1,203,200), Loss: 206.5724 (Recon: 206.5533, KL: 0.0191) Grad: 31.4089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 122/469 [00:08<00:25, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,500 (N samples: 1,216,000), Loss: 209.7084 (Recon: 209.6899, KL: 0.0185) Grad: 29.1952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 222/469 [00:16<00:17, 13.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,600 (N samples: 1,228,800), Loss: 208.4366 (Recon: 208.4177, KL: 0.0189) Grad: 28.9136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 322/469 [00:23<00:10, 13.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,700 (N samples: 1,241,600), Loss: 203.3964 (Recon: 203.3781, KL: 0.0183) Grad: 33.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 422/469 [00:30<00:03, 14.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,800 (N samples: 1,254,400), Loss: 209.3727 (Recon: 209.3529, KL: 0.0198) Grad: 29.8158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:34<00:00, 13.64it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 33.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.4181 (BCE: 206.3991, KLD: 0.0191)\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 54/469 [00:04<00:31, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,900 (N samples: 1,267,200), Loss: 206.8290 (Recon: 206.8102, KL: 0.0187) Grad: 35.6232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 152/469 [00:11<00:23, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,000 (N samples: 1,280,000), Loss: 205.6137 (Recon: 205.5962, KL: 0.0176) Grad: 33.8008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 254/469 [00:19<00:16, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,100 (N samples: 1,292,800), Loss: 201.6289 (Recon: 201.6104, KL: 0.0185) Grad: 33.2052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 354/469 [00:26<00:08, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,200 (N samples: 1,305,600), Loss: 205.4520 (Recon: 205.4329, KL: 0.0191) Grad: 30.6301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 454/469 [00:34<00:01, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,300 (N samples: 1,318,400), Loss: 199.3132 (Recon: 199.2948, KL: 0.0183) Grad: 32.3106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:35<00:00, 13.18it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 32.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2951 (BCE: 206.2766, KLD: 0.0184)\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 84/469 [00:06<00:30, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,400 (N samples: 1,331,200), Loss: 201.5035 (Recon: 201.4840, KL: 0.0195) Grad: 29.0540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 184/469 [00:14<00:23, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,500 (N samples: 1,344,000), Loss: 209.9569 (Recon: 209.9388, KL: 0.0181) Grad: 29.3167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 284/469 [00:23<00:16, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,600 (N samples: 1,356,800), Loss: 202.8642 (Recon: 202.8452, KL: 0.0190) Grad: 29.9975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 384/469 [00:31<00:07, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,700 (N samples: 1,369,600), Loss: 206.1692 (Recon: 206.1500, KL: 0.0191) Grad: 27.6240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:39<00:00, 11.94it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 28.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.3273 (BCE: 206.3081, KLD: 0.0192)\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 15/469 [00:01<00:44, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,800 (N samples: 1,382,400), Loss: 208.1004 (Recon: 208.0824, KL: 0.0181) Grad: 29.7545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 115/469 [00:10<00:30, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,900 (N samples: 1,395,200), Loss: 204.3810 (Recon: 204.3624, KL: 0.0186) Grad: 32.1935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 215/469 [00:18<00:22, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,000 (N samples: 1,408,000), Loss: 213.3065 (Recon: 213.2870, KL: 0.0195) Grad: 30.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 315/469 [00:27<00:13, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,100 (N samples: 1,420,800), Loss: 202.4569 (Recon: 202.4389, KL: 0.0180) Grad: 25.9083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 415/469 [00:36<00:04, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,200 (N samples: 1,433,600), Loss: 219.1089 (Recon: 219.0900, KL: 0.0190) Grad: 47.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:41<00:00, 11.40it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 28.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2962 (BCE: 206.2770, KLD: 0.0192)\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 46/469 [00:03<00:35, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,300 (N samples: 1,446,400), Loss: 202.9490 (Recon: 202.9301, KL: 0.0190) Grad: 32.2805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 146/469 [00:12<00:27, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,400 (N samples: 1,459,200), Loss: 204.3989 (Recon: 204.3808, KL: 0.0181) Grad: 31.3361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 246/469 [00:21<00:18, 11.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,500 (N samples: 1,472,000), Loss: 206.9918 (Recon: 206.9735, KL: 0.0183) Grad: 30.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 347/469 [00:31<00:10, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,600 (N samples: 1,484,800), Loss: 205.7858 (Recon: 205.7670, KL: 0.0188) Grad: 27.8878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 447/469 [00:39<00:01, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,700 (N samples: 1,497,600), Loss: 209.1734 (Recon: 209.1546, KL: 0.0188) Grad: 36.9098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:41<00:00, 11.28it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 29.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2248 (BCE: 206.2052, KLD: 0.0197)\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 78/469 [00:06<00:33, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,800 (N samples: 1,510,400), Loss: 206.0940 (Recon: 206.0761, KL: 0.0179) Grad: 28.4337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 178/469 [00:15<00:24, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,900 (N samples: 1,523,200), Loss: 205.5359 (Recon: 205.5160, KL: 0.0199) Grad: 26.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 278/469 [00:23<00:15, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,000 (N samples: 1,536,000), Loss: 202.2576 (Recon: 202.2378, KL: 0.0197) Grad: 31.2273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 378/469 [00:31<00:07, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,100 (N samples: 1,548,800), Loss: 208.6013 (Recon: 208.5824, KL: 0.0188) Grad: 29.8250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:39<00:00, 11.94it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 28.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.1948 (BCE: 206.1759, KLD: 0.0189)\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 8/469 [00:00<00:35, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,200 (N samples: 1,561,600), Loss: 206.7995 (Recon: 206.7802, KL: 0.0193) Grad: 30.9836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 108/469 [00:08<00:29, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,300 (N samples: 1,574,400), Loss: 206.0931 (Recon: 206.0755, KL: 0.0177) Grad: 38.4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 208/469 [00:18<00:21, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,400 (N samples: 1,587,200), Loss: 207.1494 (Recon: 207.1308, KL: 0.0186) Grad: 29.1722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 308/469 [00:26<00:12, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,500 (N samples: 1,600,000), Loss: 207.2233 (Recon: 207.2033, KL: 0.0199) Grad: 35.9355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 408/469 [00:34<00:04, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,600 (N samples: 1,612,800), Loss: 204.7335 (Recon: 204.7154, KL: 0.0180) Grad: 27.2264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:39<00:00, 11.94it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 30.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2861 (BCE: 206.2667, KLD: 0.0194)\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 40/469 [00:03<00:33, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,700 (N samples: 1,625,600), Loss: 207.9534 (Recon: 207.9338, KL: 0.0196) Grad: 25.2438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 140/469 [00:10<00:24, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,800 (N samples: 1,638,400), Loss: 213.1656 (Recon: 213.1469, KL: 0.0187) Grad: 27.3641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 240/469 [00:18<00:16, 14.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,900 (N samples: 1,651,200), Loss: 204.3403 (Recon: 204.3209, KL: 0.0195) Grad: 38.0469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 340/469 [00:25<00:08, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,000 (N samples: 1,664,000), Loss: 207.9909 (Recon: 207.9718, KL: 0.0191) Grad: 28.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 440/469 [00:31<00:01, 15.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,100 (N samples: 1,676,800), Loss: 206.2950 (Recon: 206.2766, KL: 0.0183) Grad: 34.6733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:33<00:00, 13.84it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 32.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2554 (BCE: 206.2360, KLD: 0.0194)\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 72/469 [00:04<00:24, 15.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,200 (N samples: 1,689,600), Loss: 209.6332 (Recon: 209.6153, KL: 0.0179) Grad: 29.6409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 172/469 [00:11<00:18, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,300 (N samples: 1,702,400), Loss: 207.1798 (Recon: 207.1610, KL: 0.0187) Grad: 28.2708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 272/469 [00:17<00:11, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,400 (N samples: 1,715,200), Loss: 210.3784 (Recon: 210.3602, KL: 0.0182) Grad: 31.3733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 372/469 [00:23<00:05, 16.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,500 (N samples: 1,728,000), Loss: 207.6621 (Recon: 207.6438, KL: 0.0183) Grad: 35.0754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:29<00:00, 15.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,600 (N samples: 1,740,800), Loss: 202.2662 (Recon: 202.2484, KL: 0.0179) Grad: 35.3815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|| 79/79 [00:02<00:00, 33.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2249 (BCE: 206.2070, KLD: 0.0179)\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 103/469 [00:05<00:20, 17.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,700 (N samples: 1,753,600), Loss: 200.9343 (Recon: 200.9158, KL: 0.0185) Grad: 27.9328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 204/469 [00:10<00:12, 21.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,800 (N samples: 1,766,400), Loss: 203.2392 (Recon: 203.2211, KL: 0.0181) Grad: 28.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 301/469 [00:15<00:07, 21.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,900 (N samples: 1,779,200), Loss: 209.2121 (Recon: 209.1922, KL: 0.0199) Grad: 32.2564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 402/469 [00:20<00:03, 19.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,000 (N samples: 1,792,000), Loss: 208.8466 (Recon: 208.8277, KL: 0.0190) Grad: 35.7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.68it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 34.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2491 (BCE: 206.2299, KLD: 0.0192)\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 34/469 [00:01<00:21, 20.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,100 (N samples: 1,804,800), Loss: 210.6464 (Recon: 210.6274, KL: 0.0190) Grad: 27.7590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 135/469 [00:06<00:15, 21.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,200 (N samples: 1,817,600), Loss: 203.3519 (Recon: 203.3327, KL: 0.0191) Grad: 25.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 235/469 [00:11<00:10, 21.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,300 (N samples: 1,830,400), Loss: 209.8142 (Recon: 209.7956, KL: 0.0186) Grad: 31.8506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 334/469 [00:16<00:07, 18.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,400 (N samples: 1,843,200), Loss: 200.9371 (Recon: 200.9178, KL: 0.0193) Grad: 32.2638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 431/469 [00:21<00:01, 20.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,500 (N samples: 1,856,000), Loss: 205.7726 (Recon: 205.7540, KL: 0.0186) Grad: 29.8378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.86it/s]\n",
      "Testing: 100%|| 79/79 [00:03<00:00, 25.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.3274 (BCE: 206.3090, KLD: 0.0185)\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 64/469 [00:03<00:23, 16.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,600 (N samples: 1,868,800), Loss: 205.2931 (Recon: 205.2734, KL: 0.0197) Grad: 33.2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 163/469 [00:09<00:18, 16.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,700 (N samples: 1,881,600), Loss: 209.0364 (Recon: 209.0176, KL: 0.0188) Grad: 30.6333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 265/469 [00:14<00:09, 20.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,800 (N samples: 1,894,400), Loss: 204.0299 (Recon: 204.0112, KL: 0.0187) Grad: 30.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 365/469 [00:19<00:05, 20.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,900 (N samples: 1,907,200), Loss: 201.2203 (Recon: 201.2001, KL: 0.0202) Grad: 36.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 465/469 [00:24<00:00, 20.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,000 (N samples: 1,920,000), Loss: 216.6444 (Recon: 216.6253, KL: 0.0191) Grad: 38.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:24<00:00, 18.77it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 35.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.3302 (BCE: 206.3104, KLD: 0.0199)\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 96/469 [00:04<00:18, 20.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,100 (N samples: 1,932,800), Loss: 202.5483 (Recon: 202.5298, KL: 0.0185) Grad: 30.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 196/469 [00:09<00:13, 19.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,200 (N samples: 1,945,600), Loss: 211.9011 (Recon: 211.8836, KL: 0.0175) Grad: 37.3390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 295/469 [00:14<00:08, 19.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,300 (N samples: 1,958,400), Loss: 210.1778 (Recon: 210.1590, KL: 0.0189) Grad: 34.8002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 397/469 [00:19<00:03, 21.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,400 (N samples: 1,971,200), Loss: 205.8212 (Recon: 205.8028, KL: 0.0183) Grad: 27.2958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 20.19it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 35.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.3581 (BCE: 206.3390, KLD: 0.0191)\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 27/469 [00:01<00:22, 19.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,500 (N samples: 1,984,000), Loss: 206.0036 (Recon: 205.9848, KL: 0.0188) Grad: 26.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 125/469 [00:06<00:20, 16.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,600 (N samples: 1,996,800), Loss: 205.9786 (Recon: 205.9604, KL: 0.0182) Grad: 36.3649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 228/469 [00:11<00:11, 20.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,700 (N samples: 2,009,600), Loss: 203.7919 (Recon: 203.7739, KL: 0.0180) Grad: 32.8102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 327/469 [00:16<00:06, 20.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,800 (N samples: 2,022,400), Loss: 211.9989 (Recon: 211.9799, KL: 0.0191) Grad: 36.1909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 427/469 [00:21<00:02, 20.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,900 (N samples: 2,035,200), Loss: 208.4116 (Recon: 208.3935, KL: 0.0181) Grad: 23.8843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.56it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 35.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.3458 (BCE: 206.3261, KLD: 0.0197)\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 57/469 [00:02<00:20, 20.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,000 (N samples: 2,048,000), Loss: 213.0037 (Recon: 212.9842, KL: 0.0195) Grad: 30.4698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 158/469 [00:07<00:15, 19.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,100 (N samples: 2,060,800), Loss: 198.8715 (Recon: 198.8535, KL: 0.0180) Grad: 26.9254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 257/469 [00:12<00:10, 20.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,200 (N samples: 2,073,600), Loss: 203.3353 (Recon: 203.3176, KL: 0.0178) Grad: 30.2998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 359/469 [00:17<00:05, 20.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,300 (N samples: 2,086,400), Loss: 206.0695 (Recon: 206.0498, KL: 0.0197) Grad: 30.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 457/469 [00:22<00:00, 19.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,400 (N samples: 2,099,200), Loss: 209.7134 (Recon: 209.6951, KL: 0.0183) Grad: 35.9487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.85it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 35.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2810 (BCE: 206.2629, KLD: 0.0181)\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 89/469 [00:04<00:18, 20.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,500 (N samples: 2,112,000), Loss: 201.1052 (Recon: 201.0864, KL: 0.0188) Grad: 32.0713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 189/469 [00:09<00:13, 20.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,600 (N samples: 2,124,800), Loss: 212.9391 (Recon: 212.9199, KL: 0.0192) Grad: 33.2166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|   | 288/469 [00:14<00:08, 21.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,700 (N samples: 2,137,600), Loss: 201.6928 (Recon: 201.6745, KL: 0.0183) Grad: 30.7492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 390/469 [00:19<00:03, 21.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,800 (N samples: 2,150,400), Loss: 201.5771 (Recon: 201.5576, KL: 0.0194) Grad: 31.5253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.52it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 35.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2937 (BCE: 206.2753, KLD: 0.0184)\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 20/469 [00:00<00:20, 21.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,900 (N samples: 2,163,200), Loss: 206.7576 (Recon: 206.7395, KL: 0.0181) Grad: 27.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 120/469 [00:05<00:16, 21.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,000 (N samples: 2,176,000), Loss: 208.4181 (Recon: 208.3994, KL: 0.0187) Grad: 32.2122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 219/469 [00:10<00:12, 20.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,100 (N samples: 2,188,800), Loss: 207.5348 (Recon: 207.5168, KL: 0.0180) Grad: 29.5715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 321/469 [00:15<00:06, 21.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,200 (N samples: 2,201,600), Loss: 208.2116 (Recon: 208.1928, KL: 0.0188) Grad: 33.5993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 419/469 [00:20<00:02, 21.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,300 (N samples: 2,214,400), Loss: 206.6594 (Recon: 206.6409, KL: 0.0185) Grad: 30.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.69it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 35.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2059 (BCE: 206.1875, KLD: 0.0184)\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 52/469 [00:02<00:19, 21.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,400 (N samples: 2,227,200), Loss: 202.4673 (Recon: 202.4492, KL: 0.0181) Grad: 28.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 150/469 [00:07<00:14, 21.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,500 (N samples: 2,240,000), Loss: 206.3080 (Recon: 206.2884, KL: 0.0197) Grad: 28.6811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 251/469 [00:12<00:10, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,600 (N samples: 2,252,800), Loss: 205.4728 (Recon: 205.4546, KL: 0.0182) Grad: 33.1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 349/469 [00:16<00:05, 20.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,700 (N samples: 2,265,600), Loss: 209.3192 (Recon: 209.3012, KL: 0.0180) Grad: 31.6720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 452/469 [00:21<00:00, 20.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,800 (N samples: 2,278,400), Loss: 207.8420 (Recon: 207.8221, KL: 0.0199) Grad: 24.9506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 20.22it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 33.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2344 (BCE: 206.2152, KLD: 0.0191)\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 81/469 [00:03<00:17, 21.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,900 (N samples: 2,291,200), Loss: 209.2074 (Recon: 209.1879, KL: 0.0195) Grad: 33.2565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 182/469 [00:09<00:15, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,000 (N samples: 2,304,000), Loss: 206.5787 (Recon: 206.5606, KL: 0.0181) Grad: 28.2811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 283/469 [00:14<00:08, 21.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,100 (N samples: 2,316,800), Loss: 204.4892 (Recon: 204.4698, KL: 0.0194) Grad: 27.3767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 382/469 [00:19<00:04, 18.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,200 (N samples: 2,329,600), Loss: 202.8533 (Recon: 202.8338, KL: 0.0195) Grad: 32.6888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:25<00:00, 18.30it/s]\n",
      "Testing: 100%|| 79/79 [00:04<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.1730 (BCE: 206.1547, KLD: 0.0183)\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 10/469 [00:01<00:52,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,300 (N samples: 2,342,400), Loss: 200.2934 (Recon: 200.2751, KL: 0.0183) Grad: 33.6293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 113/469 [00:09<00:22, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,400 (N samples: 2,355,200), Loss: 210.9030 (Recon: 210.8842, KL: 0.0188) Grad: 36.5788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 211/469 [00:16<00:22, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,500 (N samples: 2,368,000), Loss: 207.0700 (Recon: 207.0520, KL: 0.0180) Grad: 31.7936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 313/469 [00:24<00:09, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,600 (N samples: 2,380,800), Loss: 207.8855 (Recon: 207.8669, KL: 0.0186) Grad: 30.3082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 410/469 [11:11<00:05, 11.42it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,700 (N samples: 2,393,600), Loss: 205.7005 (Recon: 205.6811, KL: 0.0195) Grad: 28.8317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [11:15<00:00,  1.44s/it]\n",
      "Testing: 100%|| 79/79 [00:01<00:00, 39.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.1857 (BCE: 206.1666, KLD: 0.0191)\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 45/469 [00:01<00:17, 24.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,800 (N samples: 2,406,400), Loss: 206.7862 (Recon: 206.7684, KL: 0.0178) Grad: 34.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 144/469 [00:06<00:13, 24.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,900 (N samples: 2,419,200), Loss: 207.1734 (Recon: 207.1545, KL: 0.0189) Grad: 29.9356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 243/469 [00:10<00:09, 23.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19,000 (N samples: 2,432,000), Loss: 207.2654 (Recon: 207.2467, KL: 0.0186) Grad: 31.9195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 345/469 [00:15<00:05, 23.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19,100 (N samples: 2,444,800), Loss: 200.4741 (Recon: 200.4556, KL: 0.0184) Grad: 30.8885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 441/469 [00:19<00:01, 24.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19,200 (N samples: 2,457,600), Loss: 210.5998 (Recon: 210.5805, KL: 0.0193) Grad: 30.7563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 22.68it/s]\n",
      "Testing: 100%|| 79/79 [00:01<00:00, 40.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2488 (BCE: 206.2304, KLD: 0.0184)\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 77/469 [00:03<00:14, 27.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19,300 (N samples: 2,470,400), Loss: 203.2613 (Recon: 203.2430, KL: 0.0183) Grad: 28.8969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 176/469 [00:06<00:11, 26.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19,400 (N samples: 2,483,200), Loss: 206.7027 (Recon: 206.6829, KL: 0.0198) Grad: 33.4840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 275/469 [00:10<00:07, 26.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19,500 (N samples: 2,496,000), Loss: 200.7854 (Recon: 200.7653, KL: 0.0201) Grad: 33.5583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 374/469 [00:14<00:03, 24.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19,600 (N samples: 2,508,800), Loss: 208.9746 (Recon: 208.9553, KL: 0.0193) Grad: 25.7420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 25.68it/s]\n",
      "Testing: 100%|| 79/79 [00:01<00:00, 42.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.4426 (BCE: 206.4239, KLD: 0.0187)\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/469 [00:00<00:24, 18.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19,700 (N samples: 2,521,600), Loss: 202.3327 (Recon: 202.3139, KL: 0.0188) Grad: 39.4191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 107/469 [00:04<00:15, 22.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19,800 (N samples: 2,534,400), Loss: 199.6752 (Recon: 199.6546, KL: 0.0206) Grad: 39.3174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 206/469 [00:08<00:11, 22.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19,900 (N samples: 2,547,200), Loss: 214.5474 (Recon: 214.5282, KL: 0.0191) Grad: 37.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 305/469 [00:13<00:07, 23.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20,000 (N samples: 2,560,000), Loss: 202.9486 (Recon: 202.9288, KL: 0.0198) Grad: 28.9684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 406/469 [00:17<00:02, 22.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20,100 (N samples: 2,572,800), Loss: 206.1707 (Recon: 206.1526, KL: 0.0180) Grad: 30.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 22.88it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 35.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2996 (BCE: 206.2807, KLD: 0.0189)\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 36/469 [00:02<00:27, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20,200 (N samples: 2,585,600), Loss: 207.4669 (Recon: 207.4486, KL: 0.0182) Grad: 30.1475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 136/469 [00:15<00:29, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20,300 (N samples: 2,598,400), Loss: 207.7685 (Recon: 207.7501, KL: 0.0184) Grad: 29.2808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 236/469 [00:21<00:11, 20.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20,400 (N samples: 2,611,200), Loss: 209.3289 (Recon: 209.3106, KL: 0.0184) Grad: 33.3577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 333/469 [00:27<00:05, 23.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20,500 (N samples: 2,624,000), Loss: 210.1557 (Recon: 210.1367, KL: 0.0190) Grad: 25.8473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 438/469 [00:34<00:01, 23.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20,600 (N samples: 2,636,800), Loss: 205.7297 (Recon: 205.7102, KL: 0.0195) Grad: 24.2579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:35<00:00, 13.14it/s]\n",
      "Testing: 100%|| 79/79 [00:01<00:00, 41.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.1724 (BCE: 206.1523, KLD: 0.0201)\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 66/469 [00:02<00:16, 23.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20,700 (N samples: 2,649,600), Loss: 203.8929 (Recon: 203.8737, KL: 0.0191) Grad: 26.7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 168/469 [00:07<00:14, 21.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20,800 (N samples: 2,662,400), Loss: 212.6350 (Recon: 212.6147, KL: 0.0203) Grad: 34.8691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 270/469 [00:11<00:07, 27.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20,900 (N samples: 2,675,200), Loss: 207.2393 (Recon: 207.2206, KL: 0.0186) Grad: 27.9010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 369/469 [00:14<00:03, 27.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21,000 (N samples: 2,688,000), Loss: 213.6239 (Recon: 213.6062, KL: 0.0177) Grad: 48.4943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 25.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21,100 (N samples: 2,700,800), Loss: 210.3328 (Recon: 210.3130, KL: 0.0199) Grad: 37.8757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|| 79/79 [00:01<00:00, 46.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.1786 (BCE: 206.1587, KLD: 0.0199)\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 101/469 [00:03<00:13, 27.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21,200 (N samples: 2,713,600), Loss: 198.8655 (Recon: 198.8475, KL: 0.0180) Grad: 37.7665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 200/469 [00:07<00:09, 27.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21,300 (N samples: 2,726,400), Loss: 202.6444 (Recon: 202.6251, KL: 0.0192) Grad: 26.4239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 299/469 [00:10<00:06, 27.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21,400 (N samples: 2,739,200), Loss: 208.7998 (Recon: 208.7814, KL: 0.0184) Grad: 33.1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 399/469 [00:14<00:02, 27.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21,500 (N samples: 2,752,000), Loss: 207.6994 (Recon: 207.6805, KL: 0.0190) Grad: 31.5034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:17<00:00, 27.20it/s]\n",
      "Testing: 100%|| 79/79 [00:01<00:00, 46.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.4133 (BCE: 206.3951, KLD: 0.0182)\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 30/469 [00:01<00:16, 26.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21,600 (N samples: 2,764,800), Loss: 200.9883 (Recon: 200.9689, KL: 0.0194) Grad: 32.4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 132/469 [00:05<00:12, 26.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21,700 (N samples: 2,777,600), Loss: 212.0909 (Recon: 212.0712, KL: 0.0196) Grad: 25.4717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 231/469 [00:08<00:09, 25.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21,800 (N samples: 2,790,400), Loss: 209.1016 (Recon: 209.0831, KL: 0.0185) Grad: 26.4139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 330/469 [00:12<00:05, 24.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21,900 (N samples: 2,803,200), Loss: 212.5936 (Recon: 212.5749, KL: 0.0187) Grad: 36.8491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 429/469 [00:16<00:01, 24.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22,000 (N samples: 2,816,000), Loss: 204.4910 (Recon: 204.4729, KL: 0.0181) Grad: 32.1388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 25.71it/s]\n",
      "Testing: 100%|| 79/79 [00:01<00:00, 44.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2273 (BCE: 206.2080, KLD: 0.0193)\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 63/469 [00:02<00:15, 25.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22,100 (N samples: 2,828,800), Loss: 206.1741 (Recon: 206.1557, KL: 0.0184) Grad: 25.1508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 162/469 [00:06<00:12, 25.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22,200 (N samples: 2,841,600), Loss: 208.0369 (Recon: 208.0173, KL: 0.0197) Grad: 23.4100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 261/469 [00:10<00:08, 24.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22,300 (N samples: 2,854,400), Loss: 206.6868 (Recon: 206.6686, KL: 0.0183) Grad: 33.6011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 360/469 [00:14<00:04, 24.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22,400 (N samples: 2,867,200), Loss: 211.2022 (Recon: 211.1836, KL: 0.0186) Grad: 28.8495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 462/469 [00:18<00:00, 24.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22,500 (N samples: 2,880,000), Loss: 202.9724 (Recon: 202.9535, KL: 0.0189) Grad: 30.4633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 24.94it/s]\n",
      "Testing: 100%|| 79/79 [00:01<00:00, 42.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2989 (BCE: 206.2795, KLD: 0.0194)\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 93/469 [00:03<00:15, 24.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22,600 (N samples: 2,892,800), Loss: 206.1752 (Recon: 206.1563, KL: 0.0189) Grad: 27.8676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 191/469 [00:08<00:14, 19.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22,700 (N samples: 2,905,600), Loss: 204.1073 (Recon: 204.0868, KL: 0.0205) Grad: 35.7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 292/469 [00:13<00:07, 22.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22,800 (N samples: 2,918,400), Loss: 202.4746 (Recon: 202.4545, KL: 0.0201) Grad: 31.4649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 391/469 [00:18<00:03, 20.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22,900 (N samples: 2,931,200), Loss: 207.5749 (Recon: 207.5551, KL: 0.0198) Grad: 25.2622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 21.01it/s]\n",
      "Testing: 100%|| 79/79 [00:01<00:00, 39.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2662 (BCE: 206.2465, KLD: 0.0197)\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 24/469 [00:01<00:20, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23,000 (N samples: 2,944,000), Loss: 208.3668 (Recon: 208.3467, KL: 0.0201) Grad: 25.5820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 122/469 [00:05<00:17, 19.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23,100 (N samples: 2,956,800), Loss: 204.8857 (Recon: 204.8658, KL: 0.0200) Grad: 30.4796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 221/469 [00:10<00:12, 20.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23,200 (N samples: 2,969,600), Loss: 203.4370 (Recon: 203.4188, KL: 0.0182) Grad: 33.8517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 323/469 [00:14<00:07, 20.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23,300 (N samples: 2,982,400), Loss: 209.8578 (Recon: 209.8380, KL: 0.0198) Grad: 39.3997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 423/469 [00:19<00:02, 19.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23,400 (N samples: 2,995,200), Loss: 213.2102 (Recon: 213.1910, KL: 0.0192) Grad: 36.1538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 21.08it/s]\n",
      "Testing: 100%|| 79/79 [00:02<00:00, 33.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 206.2543 (BCE: 206.2353, KLD: 0.0190)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")\n",
    "writer = SummaryWriter(f'runs/mnist/vae_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "prev_updates = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    prev_updates = train(\n",
    "        model, train_loader, optimizer, prev_updates, device, writer=writer\n",
    "    )\n",
    "    test(model, test_loader, prev_updates, size_latent, writer=writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "- anndata: 0.10.7\n",
    "- matplotlib: 3.8.4\n",
    "- numpy: 1.26.4\n",
    "- pytorch: 2.2.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from random import choice\n",
    "\n",
    "import anndata as ad\n",
    "from anndata.experimental import AnnLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model size\n",
    "input_layer = 10000\n",
    "layer_one = 6000\n",
    "layer_two = 3000\n",
    "layer_three = 1000\n",
    "latent_space = 200\n",
    "# Dataloaders\n",
    "batch_size = 128\n",
    "# Optimizer\n",
    "learning_rate = 1e-1\n",
    "weight_decay = 1e-8\n",
    "# Training\n",
    "folds = 5\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure\n",
    "\n",
    "The **autoencoder** is comprised of two primary components: the **encoder** and the **decoder**. The encoder is responsible for reducing the dimensionality of the input tensor. The decoder, in turn, attempts to reconstruct the original input data from the reduced representation generated by the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AEOutput:\n",
    "    \"\"\"\n",
    "    Dataclass for AE output.\n",
    "    \n",
    "    Attributes:\n",
    "        z_sample (torch.Tensor): The sampled value of the latent variable z.\n",
    "        x_recon (torch.Tensor): The reconstructed output from the VAE.\n",
    "        loss (torch.Tensor): The overall loss of the VAE.\n",
    "    \"\"\"\n",
    "    z_sample: torch.Tensor\n",
    "    x_recon: torch.Tensor\n",
    "    \n",
    "    loss: torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder (AE) class.\n",
    "\n",
    "    Args:\n",
    "        size_input_layer (int): Dimensionality of the input data.\n",
    "        size_layer_one (int): Dimensionality of hidden layer 1.\n",
    "        size_layer_two (int): Dimensionality of hidden layer 2.\n",
    "        size_layer_three (int): Dimensionality of hidden layer 3.\n",
    "        size_latent_space (int): Dimensionality of the latent space.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        size_input_layer: int,\n",
    "        size_layer_one: int,\n",
    "        size_layer_two: int,\n",
    "        size_layer_three: int,\n",
    "        size_latent_space: int,):\n",
    "        super(Autoencoder, self).__init__() # Why?\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(size_input_layer, size_layer_one),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(size_layer_one, size_layer_two),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(size_layer_two, size_layer_three),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(size_layer_three, size_latent_space)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(size_latent_space, size_layer_three),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(size_layer_three, size_layer_two),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(size_layer_two, size_layer_one),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(size_layer_one, size_input_layer),   \n",
    "        )\n",
    "\n",
    "    def encode(self, x, eps: float = 1e-8):\n",
    "       \"\"\"\n",
    "       Encodes the input data into the latent space.\n",
    "        \n",
    "       Args:\n",
    "           x (torch.Tensor): Input data.\n",
    "        \n",
    "       Returns:\n",
    "           torch.Tensor: Input data compressed to latent space.\n",
    "       \"\"\"\n",
    "       return self.encoder(x)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decodes the data from the latent space to the original input space.\n",
    "        \n",
    "        Args:\n",
    "            z (torch.Tensor): Data in the latent space.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed data in the original input space.\n",
    "        \"\"\"\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x, compute_loss: bool = True):\n",
    "        \"\"\"\n",
    "        Performs a forward pass of the AE.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            compute_loss (bool): Whether to compute the loss or not.\n",
    "        \n",
    "        Returns:\n",
    "            VAEOutput: VAE output dataclass.\n",
    "        \"\"\"\n",
    "        z = self.encode(x)\n",
    "        recon_x = self.decode(z)\n",
    "        \n",
    "        if not compute_loss:\n",
    "            return AEOutput(\n",
    "                z_sample=z,\n",
    "                x_recon=recon_x,\n",
    "                loss=None\n",
    "            )\n",
    "        \n",
    "        # compute loss terms \n",
    "        loss_recon = F.binary_cross_entropy(recon_x, x + 0.5, reduction='none').sum(-1).mean()\n",
    "        \n",
    "        return AEOutput(\n",
    "            z_sample=z,\n",
    "            x_recon=recon_x,\n",
    "            loss=loss_recon\n",
    "        )\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"../data/adata_normalized_sample.h5ad\"\n",
    "file_path = \"../data/adata_30kx10k_normalized_sample.h5ad\"\n",
    "# file_path = \"/home/ubuntu/projects/project_data/thesis/global_raw.h5ad\"\n",
    "\n",
    "adata = ad.read_h5ad(filename=file_path)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cuda = True if device == \"cuda\" else False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30000x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12490183 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does not work yet --> Data type error\n",
    "# adata.X = adata.layers[\"min_max_normalized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is divided into two sections: one for training and the other for validation following training. This division is referred to as a **\"fold\"**. The fold is created by extracting all cells from a single donor to ensure that the results are not influenced by any batch effects specific to that donor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(adata):\n",
    "    donors = adata.obs[\"donor\"].unique()\n",
    "    # Random choice for donor\n",
    "    donor = choice(donors) # --> Is random choice correct\n",
    "\n",
    "    # Create training data\n",
    "    # Remove cells from chosen donor\n",
    "    train_data = adata[adata.obs.donor != donor]\n",
    "    # Create validation data\n",
    "    val_data = adata[adata.obs.donor == donor]\n",
    "\n",
    "    # Load data\n",
    "    train_loader = AnnLoader(train_data, batch_size=batch_size, shuffle=True, use_cuda=cuda)\n",
    "    val_loader = AnnLoader(val_data, batch_size=batch_size, shuffle=True, use_cuda=cuda)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(input_layer, layer_one, layer_two, layer_three, latent_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# --------------- #\n",
      "FOLD 1\n",
      "# --------------- #\n",
      "Starting EPOCH 1 / 15\n",
      "Avg loss after BATCH 100: 1.4210562187037691e+23\n",
      "Avg loss after BATCH 200: 1.4210562187784177e+23\n",
      "Starting EPOCH 2 / 15\n",
      "Avg loss after BATCH 100: 110244999.78099062\n",
      "Avg loss after BATCH 200: 110245001.20154655\n",
      "Starting EPOCH 3 / 15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m t_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Perform optimization\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Save loss for plotting\u001b[39;00m\n\u001b[1;32m     34\u001b[0m training_losses\u001b[38;5;241m.\u001b[39mappend(t_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/software/miniconda3/envs/machine_learning/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/software/miniconda3/envs/machine_learning/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/software/miniconda3/envs/machine_learning/lib/python3.10/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/software/miniconda3/envs/machine_learning/lib/python3.10/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/software/miniconda3/envs/machine_learning/lib/python3.10/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    388\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PRINT_LOSS = 100\n",
    "\n",
    "training_losses = []\n",
    "for fold in range(folds):\n",
    "    # Print fold information\n",
    "    print(\"# --------------- #\")\n",
    "    print(f\"FOLD {fold + 1}\")\n",
    "    print(\"# --------------- #\")\n",
    "    \n",
    "    train_loader, val_loader = create_folds(adata)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train(True)\n",
    "        # Print epoch information\n",
    "        print(f\"Starting EPOCH {epoch + 1} / {epochs}\")\n",
    "\n",
    "        # Holds the running loss\n",
    "        running_t_loss = 0.\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            # Reconstruct input\n",
    "            reconstructed = model(batch.X)\n",
    "\n",
    "            # Calculate batch loss\n",
    "            t_loss = loss_function(reconstructed, batch.X)\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Backprop\n",
    "            t_loss.backward()\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save loss for plotting\n",
    "            training_losses.append(t_loss.item())\n",
    "\n",
    "            # For command line info\n",
    "            running_t_loss += t_loss.item()\n",
    "            if idx % PRINT_LOSS == (PRINT_LOSS - 1):\n",
    "                print(f\"Avg loss after BATCH {idx + 1}: {running_t_loss / PRINT_LOSS}\")\n",
    "                running_tloss = 0.\n",
    "    \n",
    "    # Cmd info\n",
    "    print(\"Finished TRAINING process.\")\n",
    "    print(\"Start TESTING\")\n",
    "\n",
    "    # Model evaluation\n",
    "    model.eval()\n",
    "    running_v_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_loader):\n",
    "            reconstructed = model(batch.X)\n",
    "            v_loss = loss_function(reconstructed, batch.X)\n",
    "            running_v_loss += v_loss.item()\n",
    "\n",
    "    print(f\"Avg loss in validation FOLD: {running_v_loss / idx + 1}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8947492d40>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAHgCAYAAAAc+uEmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABAX0lEQVR4nO3deXhUVb7u8TdzgBACgQRoBBIUBEFAUBBksgWHCDIIR0Cwj4o0oCDaDo3a53gU04q0E5BWD63YhEEFW7nIICAyTyqTgEAQCB0JUwYImavuH5yUhFQVqb2rKlWp7+d5fJS9V9Ve9bv7cN9ea6+1g7Kzs60CAACAzwuu6g4AAACgcghuAAAAfoLgBgAA4CcIbgAAAH6C4AYAAOAnCG4AAAB+guAGAADgJwhuAAAAfoLgBgAA4CcIbgAAAH4iYILbwoUL9eSTT6p3796Ki4tTTEyMUlNT3fb9O3bs0PDhw5WYmKi4uDh16tRJU6dOVX5+vtuuAQAAAltoVXfAW1599VWlp6crNjZW8fHxSk9Pd9t3f/XVV3r44YcVEhKiAQMGKC4uTlu3btW0adO0fv16ffnll4qIiHDb9QAAQGAKmBG39957T7t371ZaWpoefvhht31vfn6+Jk+erKCgIK1YsUIffvihpk6dqm+++UZjxozRli1bNGvWLLddDwAABK6ACW69e/dW06ZNK93+9OnT+vOf/6yOHTsqLi5OiYmJGjVqlPbt21eu3datW3X27FklJSWpQ4cOtuNBQUF64YUXJEn/+Mc/ZLVa3fI7AABA4AqY4OaKX375Rb1799bf//53JSYm6rHHHlPfvn21evVq9e3bVzt27LC1PXXqlCSpWbNmFb4nJiZGMTExSk9P19GjR73VfQAAUE0FzDNurvjjH/+ozMxMLV68WH369LEdf+aZZ9SnTx9NnDhRmzZtkiTVr19fknTs2LEK35OTk6Ps7GxJ0uHDh5WQkOD5zgMAgGqLEbcr7Nq1S1u3btXw4cPLhTZJuvbaazV69Gjt27fPNmV6yy23KDo6WkuXLtWuXbvKtZ86dartv3NycjzfeQAAUK0x4naFsmnQU6dOKTk5ucL5Q4cO2f7dpk0bRUVF6dVXX9XEiRPVr18/3XfffYqLi9O2bdu0c+dOtWzZUgcPHlRISIhXfwcAAKh+CG5XyMrKkiStWLFCK1ascNguLy/P9t+jR49Wo0aN9M477+jrr79WaWmpOnTooC+//FJvv/22Dh48qNjYWI/3HQAAVG8EtyvUrl1bkvTGG2/oscceq/Tn+vbtq759+1Y4PnbsWAUHB6t9+/Zu6yMAAAhMPON2hc6dO0uStm/fbvq7tmzZouPHj+uOO+5QnTp1TH8fAAAIbAS3K3Tq1EmdO3fW559/rsWLF1c4b7FYtGHDhnLHcnNzK7T79ddfNXHiRIWGhmrKlCke6y8AAAgcQdnZ2QGxM+wnn3yizZs3S5L27dunXbt2qWvXrrYtOpKSknTvvfdKko4ePar+/fsrPT1dN998szp06KCIiAidOHFC27dv15kzZ5SZmWn77mnTpunTTz9V165d1aBBA504cULLli3TxYsX9d5772nEiBHe/8EAAKDaCZhn3DZv3qz58+eXO7ZlyxZt2bJFktS0aVNbcGvevLnWr1+vGTNm6Ouvv9bcuXMVEhKi+Ph4devWTQMGDCj3Pbfccos2btyo5cuXKzs7W/Xq1VPfvn01adIknm0DAABuEzAjbgAAAP6OZ9wAAAD8BMENAADATxDcAAAA/ATBDQAAwE8Q3AAAAPwEwc2kgoICHTlyRAUFBVXdFZ9DbeyjLo5RG/uoi2PUxj7q4pi/14bg5galpaVV3QWfRW3soy6OURv7qItj1MY+6uKYP9eG4AYAAOAnCG4AAAB+guAGAADgJwhuAAAAfoLgBgAA4CcIbgAAAH6C4AYAAOAnCG4AAAB+guAGAADgJwhuAAAAfoLg5iFWq1WHc4q1NbNQxRZrVXcHAABUA6FV3YHqqNhi1aPfndOXRy+9wLZZVIiW3F1fTaMoNwAAMI4RNw/4LO2iLbRJ0rELpXppe04V9ggAAFQHBDcPeH5bxZB2eZADAAAwguDmAblFPNMGAADcj+AGAADgJwhuAAAAfoLgBgAA4CcIbgAAAH6C4AYAAOAnCG4AAAB+guAGAADgJwhuAAAAfoLgBgAA4CcIbgAAAH6C4AYAAOAnCG4AAAB+guAGAADgJwhuAAAAfoLgBgAA4CcIbgAAAH6C4AYAAOAnCG5eZLVaq7oLAADAjxHcvIjYBgAAzCC4eREDbgAAwAyCmxdZqroDAADArxHcvIgRNwAAYAbBzYvIbQAAwAyCmxcx4gYAAMwguHkRuQ0AAJhBcPMiK9ENAACYQHDzIqZKAQCAGQQ3LyK3AQAAMwhuXkRwAwAAZvhFcLNarfrqq6907733qlWrVmrUqJE6d+6sJ598UkePHq3q7lUaU6UAAMAMvwhuL774okaPHq3Dhw8rKSlJjz32mJo1a6Y5c+aoR48e2rdvX1V3sVLIbQAAwIzQqu7A1WRmZiolJUVNmzbVhg0bFB0dbTs3a9YsTZkyRTNnztTMmTOrsJeVw4gbAAAww+dH3I4fPy6LxaKuXbuWC22SdOedd0qSzpw5UxVdAwAA8CqfD24tWrRQeHi4tmzZovPnz5c7t3LlSklSjx49qqJrLmPADQAAmOHzU6X16tXTSy+9pJdeekldunTR3XffraioKO3bt09r167VH/7wB40dO7aqu1kpVuZKAQCACT4f3CTpiSeeUMOGDTV58mTNnj3bdrxLly4aNmyYwsLCrvodBQUFHulbUVFRuX87k19YqALfH+R0G1dqE0ioi2PUxj7q4hi1sY+6OOaLtYmMjKx026Ds7GyfHwaaNm2a3njjDT3//PN64IEHFBMToz179uiFF17Qzp079dFHH2nAgAFOv+PIkSMqLS31Sn9v3lDT7vGVXS6q7tUzJgAACBAhISFKTEysdHufD27fffed7rvvPo0fP16vvfZauXNnzpxRhw4dFBMTo7179zr9Hk+OuGVmZio+Pl7h4eGSpIbzz9ptu2dQXTWIDKwRtytrA+riDLWxj7o4Rm3soy6O+WJtXBlx8/mpUmcLEOrXr682bdpo27ZtOnv2rGJjYx1+jytFMSI8PPyq14iIiFBkZIhH++GLKlObQERdHKM29lEXx6iNfdTFMX+tjc8P/5TNQTva8qPsuK+kZmdYmwAAAMzw+eDWtWtXSZc2283JySl3bt68eTpy5Ig6dOig2rVrV0X3XEJuAwAAZvj8VOnAgQP10UcfacOGDerUqZPuvvtu2zNt3377rSIiIpScnFzV3awUghsAADDD54NbSEiIFi1apL///e9avHixFi1apKKiIsXFxWno0KGaPHmy2rRpU9XdrBSmSgEAgBk+H9ykSw/1T5o0SZMmTarqrphCbgMAAGb4/DNu1QlvTgAAAGYQ3LyI2AYAAMwguHkRwQ0AAJhBcPMiZkoBAIAZBDcvIrcBAAAzCG4AAAB+guDmRUyVAgAAMwhuXkRuAwAAZhDcvIgRNwAAYAbBzYusjLkBAAATCG5eRGwDAABmENy8iKlSAABgBsHNi8htAADADIKbFxHcAACAGQQ3L2KqFAAAmEFw8yJyGwAAMIPg5kWMuAEAADMIbl5EbgMAAGYQ3LyI4AYAAMwguHmRlblSAABgAsHNi4htAADADIKbFzHgBgAAzCC4eRG5DQAAmEFw8yJG3AAAgBkENy8itwEAADMIbl5EcAMAAGYQ3LyIqVIAAGAGwc2LrIy5AQAAEwhuXsSIGwAAMIPg5kXkNgAAYAbBzYsIbgAAwAyCmxcxVQoAAMwguHkRuQ0AAJhBcPMighsAADCD4OZFTJUCAAAzCG5eRG4DAABmENy8iBE3AABgBsHNq0huAADAOIKbFxHbAACAGQQ3L2KqFAAAmEFw8yJyGwAAMIPg5kUENwAAYAbBzYuYKgUAAGYQ3LyI3AYAAMwguHkRI24AAMAMgpsXkdsAAIAZBDcvshLdAACACQQ3N7M6mQ9lqhQAAJhBcHMzZ9mM3AYAAMwguLmZs1E1RtwAAIAZBDc3Y8QNAAB4CsHNzQhuAADAUwhubsZUKQAA8BSCm5sx4gYAADyF4OZmjKoBAABPIbi5mdMRN0IdAAAwgeDmZs7ejsCbEwAAgBkENzdjcQIAAPAUgpubsTgBAAB4CsHNzQhuAADAUwhubsZUKQAA8BSCm5sx4gYAADyF4OZmTkfcvNcNAABQDRHcvIipUgAAYAbBzc2YKgUAAJ7iV8FtyZIlGjhwoBISEtSwYUPdeOONeuSRR3TixImq7pqN1cmwmrNzAAAAVxNa1R2oDKvVqsmTJ+vjjz9WQkKChgwZoqioKP3666/auHGj0tPT1aRJk6rupiRG3AAAgOf4RXB7//339fHHH2vMmDH661//qpCQkHLnS0pKqqhnFRHcAACAp/j8VGl+fr5ef/11NW/eXMnJyRVCmySFhvpO/mQfNwAA4Cm+k3gc+Pbbb5WVlaURI0aotLRUX3/9tdLS0lSnTh317t1biYmJVd3FchhxAwAAnuLzwe3HH3+UdGlU7bbbbtOhQ4ds54KDgzV+/Hi9+uqrV/2egoICj/SvqKio3L8LCixO2hZ7rB++6Mra4BLq4hi1sY+6OEZt7KMujvlibSIjIyvd1ueD25kzZyRJM2bMUPv27bVmzRq1bNlSu3fv1pNPPqkZM2YoISFBjzzyiNPvycjIUGlpqcf6mZmZeam/RZJU026bs1nnlJ7uuT74qrLaoDzq4hi1sY+6OEZt7KMujvlKbUJCQlyaPfT54GaxXBrBCg8PV2pqqho1aiRJ6tatm+bMmaPu3btrxowZVw1ujRs39kj/ioqKlJmZqfj4eIWHhyvsokVSlt22devW0zXXVD5V+7sra4NLqItj1MY+6uIYtbGPujjm77Xx+eAWHR0tSerQoYMttJVp3bq1mjdvriNHjig7O1sxMTEOv8eVYUgjwsPDFRkZqXAno3qhoWEe74cvKqsNyqMujlEb+6iLY9TGPurimL/WxudXlV533XWSpDp16tg9X3bcV54dc744geUJAADAOJ8Pbj169JAkHTx4sMK54uJiHTlyRLVq1VL9+vW93TW7nL85wYsdAQAA1Y7PB7eEhATdfvvtOnLkiD755JNy59566y3l5OQoKSnJZ/ZyYzsQAADgKb6Rdq5i+vTp6tevnyZOnKilS5fquuuu0+7du7Vu3Tpdc801euWVV6q6izZOgxvJDQAAmODzI27SpVG3b7/9ViNGjNDOnTv1/vvv68iRIxozZozWrFmj+Pj4qu6ijdM3J3ivGwAAoBryixE3SWrSpIlmzZpV1d24KqZKAQCAp/jFiFt1wVQpAAAwg+DmZkyVAgAATyG4uRlTpQAAwFMIbm7mdMSNuVIAAGACwc3NnL0dgdgGAADMILi5mdNwRnIDAAAmENzcjMUJAADAUwhubmZxco7gBgAAzCC4uZnzxQne6wcAAKh+CG5uxnYgAADAUwhubsYzbgAAwFMIbm7mdMSN5AYAAEwguLkZU6UAAMBTCG5u5uztCLw5AQAAmEFwczNG3AAAgKcQ3NyMxQkAAMBTCG5exEwpAAAwg+DmZkyVAgAATyG4uRlTpQAAwFMIbm7GPm4AAMBTCG5uxlQpAADwFIKbmzkdVSO5AQAAEwhubmZ1ks6cnQMAALgagpubsTgBAAB4CsHNzVicAAAAPIXg5mY84gYAADyF4OZmTqdKSW4AAMAEgpubMeIGAAA8heDmZgQ3AADgKQQ3N2OqFAAAeIrHg1tubq4OHjyo4uJiT1/KJzDiBgAAPMV0cNu1a5emTp2qNWvWlDuen5+vxx57TM2bN1fXrl11/fXX66uvvjJ7OZ/nfB83ohsAADDOdHBLTU3V9OnTZb0isbz22mv67LPPZLVaZbVade7cOT366KPav3+/2Uv6OCdvTiC3AQAAE0wHt61btyoyMlJ9+vSxHSssLNScOXMUGhqq+fPn6+jRoxo7dqyKi4uVkpJi9pI+jalSAADgKaaD28mTJ9WwYUMFB//2VVu2bNH58+fVr18/3XXXXapTp47+67/+S1FRUdq4caPZS/o0FicAAABPMR3csrKyVK9evXLHtm/frqCgIPXt29d2rEaNGmrWrJkyMjLMXtKnMeIGAAA8xXRwq1Gjhs6cOVPu2ObNmyVJt956a7nj4eHh5UbmqiPeVQoAADzFdIpq2bKljh8/blt0cOrUKW3YsEGxsbFq1apVuba//vqr6tevb/aSPs35qlIAAADjTAe3wYMHy2q1aujQoXrhhRc0cOBAFRcXa9CgQeXapaen6+TJk0pMTDR7SZ/GVCkAAPCUULNf8Oijj2rZsmVav369Zs2aJUlq0aKFnn322XLtvvjiC0lSjx49zF7Sp5zKt+iFA+E6uDNLHetHqM/vIhy2ZaoUAACYYTq4hYWF6V//+peWL1+ugwcPqkmTJkpKSlKNGjXKtQsJCdEf//hH3XfffWYv6TOsVquGfZurAzmhkiw6eiFfXxzNd9yeMTcAAGCC6eAmScHBwbrnnnt0zz33OGwzYcIEd1zKp/x4plgHckor3Z4RNwAAYEb1XuLpYV86GV2zh9wGAADMMB3czpw5o++++06HDx+ucO6TTz5Rz5491bJlSz3wwAN22wQSghsAADDDdHD74IMPNGjQIG3fvr3c8Tlz5ujJJ5/Unj17dPr0aa1YsUL9+/fXuXPnzF7SbzFVCgAAzDAd3NavX6+QkBD179+/3PE333xTkjR+/HjNnTtXt956qzIzM20rTwMRuQ0AAJhhOrilp6crPj5eUVFRtmM7d+7UiRMn1LlzZ02dOlVJSUn66KOPFBISohUrVpi9pM9wNYgR3AAAgBmmg9vZs2cVHx9f7tiWLVskSUlJSbZj8fHxSkxM1NGjR81e0m8xVQoAAMwwHdyCgoKUl5dX7tiOHTsUFBSkbt26lTseHR2toqIis5f0GUEutie3AQAAM0wHt2bNmunIkSPKysqSJBUVFWn16tWKjIxUx44dy7U9e/asYmNjzV7Sb1kZcgMAACaYDm533HGHiouL9cgjj2jZsmV6/PHHlZ2drd///vcKDf1tf9+cnBwdPXpUv/vd78xe0m8R2wAAgBmm35wwadIkLVq0SN9++63Wrl0rq9WqiIiICu8qXb58uaxWq2699Vazl/RbBDcAAGCG6eBWv359rV69Wu+++64OHTqkJk2aaOzYsWrdunW5dps3b1bbtm115513mr2k/yK5AQAAE9zyrtJGjRopOTnZaZu3337bHZfya+Q2AABgBu8q9SKCGwAAMMMtI25lzp49q7Vr1+rgwYO6cOGCoqKi1KpVK/Xq1SugV5OWYVEpAAAwwy3BraioSP/93/+tf/zjH3b3aYuIiNAjjzyiv/zlLwoPD3fHJf0SuQ0AAJhhOrhZLBaNHDlSq1evltVqVYMGDXTdddepYcOGOnnypA4fPqxTp05p1qxZOnjwoBYuXKigIFe3rq0eGHEDAABmmA5uqampWrVqlaKjo/Xqq69q+PDh5fZvKy0t1fz58/XSSy9p1apVSk1N1YMPPmj2sn6J3AYAAMwwvThhwYIFCgoK0ieffKJRo0aVC22SFBISogcffFAff/yxrFar5s+fb/aSfstKdAMAACaYDm4//fSTmjZtql69ejlt16tXLzVv3lw//fST2Uv6LaZKAQCAGaaDW35+vurVq1eptnXr1lVBQYHZS/otchsAADDDdHCLj4/XoUOHlJ+f77Rdfn6+Dh06pLi4OLOX9FuMuAEAADNMB7cePXooLy9PU6ZMcdruxRdfVF5ennr27Gn2kj7D1RxGbgMAAGaYDm6TJk1SWFiY5syZo9tuu03z58/Xrl27dPLkSe3atUsLFixQz5499dFHHyk8PFwTJ0403el33nlHMTExiomJ0fbt201/n7cQ3AAAgBmmtwNp2bKl/v73v2v8+PH66aefNGHChAptrFarIiMjlZKSopYtW5q63s8//6zXXntNtWrVUl5enqnvMsvV3eiYKgUAAGa45V2lgwYN0rp16zRy5EjFxcXJarXa/omLi9OoUaO0bt06DRw40NR1SktLNW7cOLVt21ZJSUnu6LpXkdsAAIAZbntX6XXXXacZM2ZIknJzc23vKo2Ojra16d+/v3Jzc/Xdd98Zusbbb7+tvXv36rvvvtO7777rln57E8ENAACY4daXzJeJjo4uF9jK7Nu3T1lZWYa+c9++fXr99df1pz/9Sa1btzbbxarBXCkAADDBI8HN3UpKSjR+/Hi1bNlSkydPNvQdntg/rqS0xLX2FktA7WNXVFRU7t+4hLo4Rm3soy6OURv7qItjvlibyMjISrf1i+A2ffp07d27V6tWrVJYWJih78jIyFBpaalb+3U+N0xS5fuTn1+g9PQct/bBH2RmZlZ1F3wSdXGM2thHXRyjNvZRF8d8pTYhISFKTEysdHufD2579uzRm2++qSeeeEIdOnQw/D2NGzd2X6f+T+2zedK/Kz+CFhEZqWuuCZwNiIuKipSZman4+HiFh4dXdXd8BnVxjNrYR10cozb2URfH/L02Ph/cxo0bp4SEBD3//POmvseVYcjKCg0pdKl9cHCwR/rh68LDwwPyd18NdXGM2thHXRyjNvZRF8f8tTY+H9z27t0r6dKrtezp27evJGnu3Lm69957vdYvI1ibAAAAzPD54DZq1Ci7xzdt2qS0tDTdfffdql+/vpo2berlnrmO3AYAAMxwObi9/vrrhi92tRfR2/Pee+/ZPT5u3DilpaXpqaee0s0332y4T95EcAMAAGa4HNz++te/KijI1Zc9XWK1Wg1/tjpgqhQAAJjhcnDr1q1bQIevy7maw8htAADADJeD29KlSz3RD5elpKQoJSWlSvtgcTGJWRlyAwAAJrjlJfOByuLiGBqxDQAAmEFwM8HlETfPdAMAAAQIgpsJrs58MlMKAADMILiZYHGxPbkNAACYQXAzgRE3AADgTQQ3E3jGDQAAeBPBzQSLi0NojLgBAAAzCG4muP6MG8kNAAAYR3AzgalSAADgTQQ3E1x/c4Jn+gEAAAIDwc0El59x81A/AABAYCC4mcA+bgAAwJsIbiawjxsAAPAmgpsJLE4AAADeRHAzgcUJAADAmwhuJlhcHEMjtwEAADMIbiYwVQoAALyJ4GaC61OlRDcAAGAcwc0ERtwAAIA3EdxMcDmIkdwAAIAJBDcTXJ36JLcBAAAzCG4mMFUKAAC8ieBmgsuvvCK5AQAAEwhuJjDiBgAAvIngZgLBDQAAeBPBzQSLq4sTSG4AAMAEgpsJLj/jxpgbAAAwgeBmAi+ZBwAA3kRwM8HVIEZuAwAAZhDcTGBxAgAA8CaCmwkWF6MYU6UAAMAMgpsJjLgBAABvIriZQHADAADeRHAzgVWlAADAmwhuJri6jxsAAIAZBDcTeHMCAADwJoKbGS4/40ZyAwAAxhHcTHD9lVcAAADGEdxMYHECAADwJoKbCWwHAgAAvIngZoLLixM81A8AABAYCG4muPyMG8kNAACYQHAzgalSAADgTQQ3E1icAAAAvIngZoKrQYzcBgAAzCC4mWBxMYqxAS8AADCD4GYCU6UAAMCbCG4msDgBAAB4E8HNBIIbAADwJoKbCa4+40ZyAwAAZhDcTHB1xM3V9gAAAJcjuJnAdiAAAMCbCG4m8IwbAADwJoKbCa4GMbYDAQAAZhDcTHB9xI3kBgAAjCO4meD6mxMAAACMI7iZwJsTAACANxHcTGBxAgAA8CaCmwmMuAEAAG8iuBlktbq+1IDcBgAAzCC4GWQkhBHcAACAGQQ3g4y8voqpUgAAYAbBzSBDwc393QAAAAGE4GYQL4wHAADe5vPBLSMjQ7NmzdKgQYPUtm1bNWjQQC1bttSoUaO0Y8eOKuuXq5vvlrEyXwoAAAwKreoOXM0HH3ygt99+WwkJCerdu7caNGigtLQ0LV26VEuXLtXs2bM1aNAgr/fL6IibVVKQW3sCAAAChc8Ht5tuuklff/21unXrVu74pk2bdN999+mpp57SPffco4iICK/2y3BwI7kBAACDfH6qdMCAARVCmyR169ZNPXr0UFZWlvbt2+f1fpkZcQMAADDC54ObM2FhYZKkkJAQr1/baAAjuAEAAKN8fqrUkfT0dK1du1bx8fG64YYbrtq+oKDArdfPL7QY+1x+gUpDAmOutKioqNy/cQl1cYza2EddHKM29lEXx3yxNpGRkZVu65fBrbi4WGPHjlVhYaFefvnlSo24ZWRkqLS01G19yCqWpJoufy79xAmF+/U4p+syMzOrugs+ibo4Rm3soy6OURv7qItjvlKbkJAQJSYmVrq93wU3i8WiCRMmaNOmTXrooYf0wAMPVOpzjRs3dms/IvMtkrJc/tzvmjRRZACNuGVmZio+Pl7h4eFV3R2fQV0cozb2URfHqI191MUxf6+NXwU3q9WqiRMn6tNPP9WwYcP01ltvVfqzrgxDVkaYxdjoXUREpCJDAyO4lQkPD3d7/asD6uIYtbGPujhGbeyjLo75a238ZtLOYrHo8ccf19y5c3X//fcrJSVFwcFV133jq0pZngAAAIzxi+BmsVj0xBNPKDU1VYMHD9b7779fJStJy/XJ4BsQeHECAAAwyuenSstG2ubNm6eBAwfqgw8+qPLQJknG1pSyHQgAADDO54Pb66+/rnnz5ikqKkrXXnutpk2bVqFNUlKSbrzxRq/2iw14AQCAt/l8cDt+/Lgk6cKFC3rzzTfttmnatKnXg5vRKU+mSgEAgFE+H9xSUlKUkpJS1d2ogBE3AADgbX6xOMEXWQxGMEbcAACAUQQ3g4yOuAEAABhFcDOIqVIAAOBtBDeDDAc35koBAIBBBDeD2McNAAB4G8HNIMNvTnBzPwAAQOAguBnEPm4AAMDbCG4GGc1f5DYAAGAUwc0g44sT3NsPAAAQOAhuBrEdCAAA8DaCm0EsTgAAAN5GcDPI8HYgJDcAAGAQwc0gpkoBAIC3EdwM4s0JAADA2whuBjHiBgAAvI3gZpDVYAQjuAEAAKMIbgaxjxsAAPA2gptBTJUCAABvI7gZxIgbAADwNoKbQRaecQMAAF5GcDOIETcAAOBtBDeDjD/jRnIDAADGENwMYnGC++SXWPVdRoF2nilSqdHCAgAQAEKrugP+ymi8YKq0vKPnS3TvsjM6kVcqSerTOEKpv6+nmqH8bwoAAK7E/+9okNEARm4r75Xvc22hTZK+zSjUgsP5VdgjAAB8F8HNIIvB5EZwK2/RLxVD2p+3ZXu/IwAA+AGCm0EWg59jqvTqCkuv3gYAgEBEcDOIxQkAAMDbCG4GsY+beVaKAQCASwhuBvGMm3lMiQIA4BqCm0GGn3Fzay/8W0Ep1QAAwBUEN4OMT5USVsoQ3AAAcA3BzSD2cTOP4AYAgGsIbgaxOMG8QoIbAAAuIbgZZGHszDRG3AAAcA3BzSD2cTOPETcAAFxDcDOIqVLzCpxsB1JitMAAAFRjBDeDGHEzz9mIG6NxAABURHAziH3czMsvIbgBAOAKgptBht+cQB6xcRbOnE2jAgAQqAhuBhnfx43kVsbZqlJG3AAAqIjgZpDRWMGI22+chbN8ghsAABUQ3AxicYJ5jLgBAOAagptBBDfzCp08x8bmvAAAVERwM4jFCeYx4gYAgGsIbgaxHYh5zleVUikAAK5EcDOIqVLznC1AcDaNCgBAoCK4GcQrr8xzuqrUyea8AAAEqtCq7oC/Mr6PG8q48oybxWrVu3suaMWJAjWuGaKnbqytG+qFebqLAAD4FIKbQRaDEYwRt9+48ozbf+3I1Xt7L9j+vOrfBdo8MF6Na4V4rH8AAPgapkoNMjpVypjbb5y91uryUFdqsWruobxy53OKrPryaL6nugYAgE8iuBnE4gTzKjvidq7QoqzCim3/vC3HI/0CAMBXEdwMYnGCec6C2+XnsgqNbr4CAED1QnAzyPAzbpf/t9WqTw7mqdOik7rp85P63/0XDG/s64+cLU7Iv2LEDQAAsDjBMHdMlS45VqCJG7Ntf/7TlhxFhQXrgWtrmuqbvyhwsuXH5fu4EdwAALiEETeD3DFVmnr4YoXzqVc8hF+dORtxu/IZNwAAQHAzzB37uK1IL6hwfv3JImNf7Icq/YxbAcENAACJ4GaY0SfRKhP4AuU5N2fbgVw+jXrWyYhbEe80BQAEEIKbQWafcbtQ7DiMBMrUYGVH3JzV419H87X+10KVGvh/kBMXSrQ5s1AZebwYFQDgH1icYJDRUTHr/0W3zIuOw8ivFy2qH1k93giQlhekyWtydDwvWzfVD9drt9Sxve2g0qtKnUyVPrYuS5LUqX6YPusbq3qVrNsnB/P07JZsFZRKNUOD9GbXOhpxXa1KfRYAgKrCiJtBRsfEyvLeyXzHozyZF6vHCFBhqVVP/BShDZklOn6hVP86mq9HvjsnSSqxWOVslrOyI25lvj9TrJR9lVvYca6gVH/emmObqr1YYtXzW3OUHSAjnQAA/0VwM8jsVOlJJ+Hs12oS3Fb8u0ini8rfYpszi7Qvq9jpaJtU/vm3ym7A+9HPlQtuK04UKu+KrUhyi61a8++Ki0UAAPAlBDeDjAa3EavPaey6c9p9tthhm8x87438FJRYNWPveU3amKWPf85TifGXsFaw8JdCu8fX/Vp41eDm6oibJJ0psFTqWbdvTtgPaN9m2O8vAAC+gmfcDDKz8nNhmvOXozsbjXMnq9Wq4avP2gLLnIMXtfVUkVJ61K3UZ9efLNKWzELdVD9cvRtHKDQ4qFyb0w4C6L/zSp1uviv99vyb1WrVWRe2Azl2oVSJ0c5va0eh8cpROAAAfI3fjLj98MMPGjp0qJo1a6bGjRvr9ttv12effVZl/fHkmJgnpkrzS6zal1VcbkRt3a+FFUaZ5h++qH1Z9kcDC0qsenZLtm787KTqfpyhAcvP6LUfz+v+b87qua0VX/h+rsh+ENqfVVzuzQj2HL9QqsErzujD/XlyJU/td9D3yx3OKbF7/Ofsq38WAICq5BcjbuvXr9eQIUMUHh6uwYMHKzo6WkuWLNGYMWN0/PhxPf30017vkye3Wst0snDBiHmH8jR5c7YKS6XYiGAtuCNWN8eF66tj9qcM5x++qKGJNXSxxKrpu85r59lidYgNU16JVZsy7W8QPPtAngY0i1SvxpGSpPPFFp3Isx9vK/OMmyStySjUGhenL3/OKVGSk/NFpVal5doPbodzS1RisVYYOQQAwFf4fHArKSnRxIkTFRQUpKVLl6p9+/aSpOeee079+vVTcnKyBg4cqBYtWni1X258FKyCk062CpGk7EKLjl8oUY3QIF0bHaqgoEtBo9hi1WdpF7X634VqUitE/3FtTV0otmjChmzbooizhRYN/eaMdgyJ15dH7U/Zvrf3gt7be6HcsW/+ffUA9faeC7bgdiDLfjiSpIyLFv1y3vF5Mw5cZcTtcG6Jw9WshaXS0fMlurZOmAd6BgCAeUHZ2dk+/WDPmjVrNHjwYI0cOVIzZ84sd27x4sV6+OGH9dRTT+kvf/mLV/v1n9+e0xcOgo9ZQZKaRNnfj6zEYtXJixZbEIsOC1KN0CAFB13a/80XNKoZrIJSq7IKvX9rRYZI8TUc7+VWUGp1uvgjvkawIkM8O+JmtVpVUlKi0NDfQjcuoTb2URfHqI191MUxI7WZ2aOubmsY4eGeVY7Pj7ht2LBBknT77bdXOFd2bOPGjV7tkyRZDL/06uqsktIvVG66NLfYqtxi38reVRkgC0ovLVAwynsreoMl9o1zgNrYR10cozb2URfHXKvN1RbUeZPPB7e0tDRJsjsVGhMTo9jYWFsbZwoK3LtHV+0Qq+JrBMlikU5XwcgSAADwjqKiIrk5RpQTGRlZ6bY+H9xyc3MlSdHR0XbP165dWxkZGVf9noyMDJWWuu+h/0mNLv0jSU/vC9e6cz5fSgAAYMDpM6eVXuqZ0cuQkBAlJiZWun3ApI3GjRt75HuLioo0Iue0tmaHMiINAEA11KB+A13TOLyquyHJD4Jb2Uhb2cjblc6fP+9wNO5yrgxDuqpTHYu+7ldHX2eUKj2vVMWll56Ba1s3TBEhQTqQXaK8Eot+VytEcZEhOpxbouzCS0/JhQZLrWPCFBR0aSVmUSWWq9YIDVJ0WLCCgqTcIotKrVKp1apSi1Q7PFiJtUNkkfRzdontePPaoaofGayj50t0usCiIElBQZcWQsTXDNHghBo6caFU208Xqdhi1c0NwnX6/za+rRcRrD3ninUq36J6EcG6u2mkbokLV1ahRdfUCtH6k4Xan1WiXy+W6uTFUhVZJKusKim16OLFi7o2Nko31I/UrxdLdbHEqroRwcoptOhcoUWFFqtqhgSpe8MI/a5WiNb9WqjjF0oVVyNYNUODdCKvVHXCgxUVFqSosGA1rBGs/Vkl+jmnWJEhQWpdN0xFpf+3R52LM9YNa4Tod7VCdCKvxKtvq7CUlio/P181atRQcIjjhRSBiNrYR10cozb2URfHjNSmcXSkIiMJbpVS9mxbWlqaOnToUO5cdna2zp49qy5dulRBz8q7oW6oOjWKqupumBMvDW1Rs9LN64Rf2r+5d+NI9bYzoFlQUKD09Gxdc02tSgfnbj6yaseTLtUlR9dcE+/R/0Hhj6iNfdTFMWpjH3VxzN9r4/NvTujevbukS9uCXKnsWFkbAACA6szng1uvXr3UvHlzff7559q9e7ft+Pnz5zVt2jSFhoZqxIgRVdhDAAAA7/D5qdLQ0FC9++67GjJkiO655x4NGTJEtWvX1pIlS3Ts2DG9+OKLuvbaa6u6mwAAAB7n88FNknr27Knly5crOTlZX3zxhYqLi3X99dfrhRde0LBhw6q6ewAAAF7hF8FNkjp16qTPP/+8qrsBAABQZXz+GTcAAABcQnADAADwEwQ3AAAAP0FwAwAA8BMENwAAAD9BcAMAAPATBDc3COEFvg5RG/uoi2PUxj7q4hi1sY+6OObPtQnKzs62VnUnAAAAcHWMuAEAAPgJghsAAICfILgBAAD4CYIbAACAnyC4AQAA+AmCGwAAgJ8guAEAAPgJgptBP/zwg4YOHapmzZqpcePGuv322/XZZ59Vdbe8pl27doqJibH7z+TJkyu0z83N1ZQpU9S2bVvFxcWpbdu2mjJlinJzc6ug9+YtXLhQTz75pHr37q24uDjFxMQoNTXVYXsjv/+zzz7T7bffrsaNG6tZs2YaOnSofvzxR0/8HLdxpS7JyckO76H4+HiH1/DHumRkZGjWrFkaNGiQ2rZtqwYNGqhly5YaNWqUduzYYfczgXDPuFqXQLpnsrOz9eyzz6pv375q2bKl4uLi1Lp1a/Xv319ffvmlrNaKW7AGwj3jal2q4z0TWtUd8Efr16/XkCFDFB4ersGDBys6OlpLlizRmDFjdPz4cT399NNV3UWviI6O1rhx4yoc79ixY7k/5+XlKSkpSXv27FGfPn10//33a+/evZo1a5bWr1+v5cuXq1atWt7qtlu8+uqrSk9PV2xsrOLj45Wenu6wrZHfP336dL3yyitq0qSJ/vM//1N5eXlavHix7rzzTi1atEg9evTw9E80xJW6lBk+fLiaNm1a7lhoqP2/mvy1Lh988IHefvttJSQkqHfv3mrQoIHS0tK0dOlSLV26VLNnz9agQYNs7QPlnnG1LmUC4Z45d+6cUlNT1blzZyUlJalu3bo6ffq0li9froceekgPPfSQ3nnnHVv7QLlnXK1Lmep0z/DmBBeVlJTo5ptvVkZGhlauXKn27dtLks6fP69+/frp0KFD2rp1q1q0aFHFPfWsdu3aSZL27Nlz1bavvfaa3njjDU2aNEkvv/xyhePPPvuspkyZ4rG+esLatWuVmJiopk2b6q233tLLL7+smTNnauTIkRXauvr709LS1KVLFzVv3lyrV69WnTp1JEn79+/X73//e8XHx2v79u0O/9KpSq7UJTk5Wa+//rqWLFlSqb8I/bkuX331lerXr69u3bqVO75p0ybdd999ioqK0oEDBxQRESEpcO4ZV+sSSPdMaWmprFZrhb6dP39effv21YEDB7R582a1bt1aUuDcM67WpTreM0yVumjdunX65ZdfdP/999tCmyTVrl1bzzzzjEpKSpxOmQUaq9Wqf/7zn4qKitKzzz5b7txTTz2lmJgYzZ071+6wvy/r3bt3hf/1Zo+R35+amqqSkhI9/fTTtr80JKl169Z64IEH9Msvv2jdunXu+zFuVNm6GOHPdRkwYECFcCJJ3bp1U48ePZSVlaV9+/ZJCqx7xpW6GOGvdZEuvUvTXjioXbu2br/9dknSkSNHJAXWPeNKXYzwh7oQ3Fy0YcMGSbLdIJcrO7Zx40av9qmqFBUVad68eZo+fbpmz55td/QtLS1Nv/76q7p06VJhmD4yMlLdunVTRkaGqf9D82VGfn+g3WObN2/WO++8o/fee08rVqxQYWGh3XbVtS5hYWGSfnvpNffMJVfW5XKBfM8UFBRo3bp1CgoK0vXXXy+Je0ayX5fLVad7xrfGQP1AWlqaJNmdCo2JiVFsbKytTXWXmZmp8ePHlzt2xx136P3331dsbKyk3+qVmJho9zvK6piWllYtp5eN/P60tDRFRUXZfXD28jbVxWuvvVbuzw0bNlRKSor69OlT7nh1rEt6errWrl2r+Ph43XDDDZK4ZyT7dblcIN0z2dnZSklJkcVi0ZkzZ/TNN9/oxIkTeu655yr8hkC6ZypTl8tVp3uG4OaistU50dHRds/Xrl1bGRkZ3uxSlXjwwQfVvXt3tW7dWuHh4fr555/1+uuv65tvvtHw4cO1YsUKBQUF2ep1+ZDz5WrXri1Jfru69GqM/P7c3Fw1aNCg0u39Vbt27ZSSkqLu3bsrLi5OGRkZWrRokf72t79p+PDh+uabb2zPUkrVry7FxcUaO3asCgsL9fLLL9tGlgL9nnFUFykw75mcnBy9/vrrtj+HhYXplVde0eOPP247Foj3TGXqIlXPe4bgBkOee+65cn/u3LmzFi5cqKSkJG3evFkrV67UnXfeWUW9gz+49957y/05MTFRzzzzjOLi4jRp0iS9+eabmjNnThX1zrMsFosmTJigTZs26aGHHtIDDzxQ1V3yCVerSyDeM82aNVN2drZKS0t14sQJLV68WK+88oq2bt2qjz/+2OcWD3hLZetSHe8ZnnFzUdlIm6PEff78eYejcdVdcHCwRowYIUnaunWrpN/qlZOTY/cz58+fL9euujHy+6Ojo53eX1e2r26GDx+u0NBQ2z1UprrUxWq1auLEifr00081bNgwvfXWW+XOB+o9c7W6OFPd7xnp0rN+zZo10+TJk/Xiiy/q//2//2cLHIF6z0jO6+KMP98zBDcXOZvjzs7O1tmzZ6vls1qVVfZs28WLFyX9Vi9Hiw+cPTNYHRj5/S1atNCFCxeUmZlZqfbVTXh4uKKiomz3UJnqUBeLxaLHH39cc+fO1f3336+UlBQFB5f/azgQ75nK1MWZ6nzP2FP2XFbZg/SBeM/Yc2VdnPHne4bg5qLu3btLktasWVPhXNmxsjaB6Pvvv5ck25YQLVq0UKNGjbR161bl5eWVa1tQUKBNmzapUaNGDh+q9XdGfn+g32NpaWnKzs6usK2Iv9fFYrHoiSeeUGpqqgYPHqz333/f7orJQLtnKlsXZ6rrPePIyZMnJf22gWyg3TOOXFkXZ/z5niG4uahXr15q3ry5Pv/8c+3evdt2/Pz585o2bZpCQ0Nt04XV1YEDB5SdnV3h+ObNmzVz5kxFRESof//+kqSgoCCNGjVKFy5c0BtvvFGu/d/+9jdlZ2dr1KhRCgoK8kbXvc7I7x85cqRCQ0M1ffr0clMf+/fv14IFC5SQkKCePXt67Td4wvnz57V3794Kx7Ozs20PF99///3lzvlzXcpGlFJTUzVw4EB98MEHDsNJIN0zrtQl0O6Z3bt32536zMrK0v/8z/9IurSKXwqse8aVulTXe4Y3Jxiwbt06DRkyRBERERoyZIhq166tJUuW6NixY3rxxRf1pz/9qaq76FHJycl699131bNnTzVt2lQRERHav3+/1qxZo+DgYL311lsaPXq0rX1eXp7uuusu26tYOnTooL1799pW8/jjK68++eQTbd68WZK0b98+7dq1S127dlVCQoIkKSkpyfZQrJHf/+abb+rVV19VkyZNdN999+nixYtatGiR8vPztWjRoir/i8ORytbl2LFjat++vTp27Kg2bdqoQYMGysjI0KpVq3Tu3Dn16dNHCxcuVHh4eLnv99e6lO3eHhUVpT/+8Y92w0lSUpJuvPFGSYFzz7hSl0C7Z55//nn985//1G233aamTZuqZs2aSk9P18qVK3XhwgUNGDBAH3/8sW1KOVDuGVfqUl3vGYKbQd9//72Sk5O1bds2FRcX6/rrr9e4ceM0bNiwqu6ax23YsEGzZ8/Wrl27dPr0aRUUFCguLk5du3bV+PHj1alTpwqfKVu6/dVXXykzM1Px8fEaMGCAnnvuOYdL2H3ZuHHjNH/+fIfnn3vuOf35z3+2/dnI7//000+VkpKiAwcOKCwsTLfccoumTJmim266ye2/x10qW5fc3Fy98sor2r59u9LT05WTk6OaNWvqhhtu0LBhwzR69GiHIy/VsS6SKrwaLBDuGVfqEmj3zObNm/XPf/5TO3bs0MmTJ3Xx4kXVrVtX7du31wMPPKAhQ4ZUmKkIhHvGlbpU13uG4AYAAOAneMYNAADATxDcAAAA/ATBDQAAwE8Q3AAAAPwEwQ0AAMBPENwAAAD8BMENAADATxDcAAAA/ATBDQA8IDk5WTExMRo3blxVdwVANUJwA+BRSUlJiomJUXJysu1Ydna2kpOTyx3zJ6mpqUpOTtbu3buruisAAkxoVXcAQOApe6eipHLvdPUX8+bN08aNG9W0aVPbi+GvFBsbq+uuu04NGzb0cu8AVGcENwDwgMcee0yPPfZYVXcDQDXDVCkAAICfILgB8Kpx48apffv2tj/HxMSU+yc1NbVce4vFooULF2rQoEFq0aKFGjRooNatW+uRRx7Rrl27HF6j7Lm67Oxsvfjii7rpppsUHx+v2267zdZu165dmjp1qu688061adNGDRo0UEJCgvr3768FCxbIarWW+97169crJiZGGzdulCRNmDChXN+TkpJsba+2OOHEiRN65pln1KlTJzVs2FBNmzbV7bffrhkzZqigoMDuZ9q1a6eYmBitX79e6enpevzxx9W6dWvFxcWpXbt2euGFF5Sbm2v3s6dPn9ZLL72krl27qlGjRmrYsKHatm2ru+++W1OnTtWpU6fsfg6Ab2GqFIBXXXvtterYsaN+/PFHSVLXrl3LnY+Li7P99/nz5zVq1CitXbtWkhQfH6/WrVvr6NGjWrRokb788kvNmjVLw4YNs3utc+fOqXfv3jp27JhatWqlVq1aKTw83HZ+0qRJ2rlzp6Kjo9WwYUPFx8fr5MmTWr9+vdavX681a9bogw8+sLWPjo5W165dtW/fPuXm5tqCZJk2bdpUqgYbN27U8OHDlZubq/DwcF1//fXKz8/XDz/8oB9++EGff/65Fi9erHr16tn9/E8//aQHH3xQBQUFuv766xUWFqbjx49r5syZ2rZtm5YtW6bQ0N/+es/IyNAdd9yhjIwMhYaGKjExUbVq1VJmZqa2bdumzZs3q3v37uVqD8A3EdwAeNXTTz+t+++/3zbqtnz5codtJ06cqLVr1+rGG2/UO++8o44dO0q6NAr3/vvv64UXXtATTzyhjh076rrrrqvw+X/84x9q27atfvjhByUkJEiS8vPzbecnTJigG264oULg+uGHHzRmzBh9+umnuueeezRw4EBJUvv27bV8+XIlJSVp48aNeuqppzRy5EiXfv/Zs2f10EMPKTc3V3feeadSUlJsAW3nzp168MEHtXPnTj3++OOaN2+e3e946aWXNHjwYL3xxhuqU6eOJOnbb7/ViBEjtH37di1YsEAPPvigrf17772njIwM9erVS7Nnz1b9+vVt53Jzc7VkyRI1btzYpd8BoGowVQrAJ33//ff64osvVLduXS1cuNAW2iQpODhY48aN06OPPqrCwkLNmjXL7neEhIRo7ty5ttAmSTVq1LD999ChQ+2Okt10002aPn26JFWYujVr9uzZOnPmjOrXr6+PPvqo3Khahw4dNHPmTEnS119/rT179tj9joSEBM2YMcMW2iSpT58+trB2ZRg+ePCgpEsLJi4PbdKlUcSRI0eqZcuW5n8cAI9jxA2AT/rXv/4lSbrrrrvUqFEju20GDBigDz74QOvWrbN7vnfv3rrmmmucXuf48eNavHixdu3apbNnz6qoqEiSVFhYKEkOn6MzauXKlZKkRx55RDVr1qxwvlevXrrxxhu1e/durVy5Uu3atavQ5qGHHlJYWFiF4126dNGHH36oI0eOlDvepEkTSZdqescddygiIsIdPwVAFSC4AfBJe/fulSRt2LBBd911l902ZQ/xZ2Rk2D3fqlUrp9d4//339dJLL9nCmj3nzp2rTHcr7dChQ5KcPw/Xpk0b7d692zZSdqVrr73W7vGy5+3y8vLKHR87dqwWLFigzz77TN98841+//vfq3Pnzuratas6dOigoKAgIz8FQBUguAHwSdnZ2ZKk9PR0paenO217+XNrl7M3olVm27Zteu655yRJY8aM0fDhw5WYmKjatWsrJCRER48eVYcOHVRSUmLsBzhw4cIFSZcWWjhStmlvWdsrOfpdwcGXnn6xWCzljrdp00YrV67UG2+8odWrV2vRokVatGiRpEujcX/605/0hz/8waXfAaBqENwA+KRatWpJurSthife9zl//nxJ0sCBAzVt2rQK59090lYmKipKOTk5yszMdNjm5MmTtrbu0r59e6WmpqqoqEg//vijNm3apKVLl2rHjh168sknJYnwBvgBFicA8LrKTM2VTSVu3brVI304duyYJOnWW2+1e97Zdc1MLZYtAti/f7/DNmXnrjbVa0R4eLi6dOmiyZMna9WqVRo/frwk6X//93/dfi0A7kdwA+B1l0/1OZrmHDRokCRp6dKl2rdvn9v7ULa6tGx063L5+fn68MMPHX62rP+ONsp1pl+/fpIubVVi77evW7fOtiCib9++Ln+/q7p16ybJfh0A+B6CGwCvi42NVXR0tCQ5XBF66623auDAgSouLtaQIUO0bNmyCm8yOHbsmN5991198sknLvehe/fuki5tz7F9+3bb8dOnT2v06NEOFzxIsm0vsmHDhgp9upqHH35Y9evX16lTp/Too48qKyvLdm7Xrl2aMGGCJCkpKcnuilIjJk2apAULFtieGyyTmZlp20rlpptucsu1AHgWz7gB8LqgoCD9x3/8hz788EMNHz5crVu3VkxMjCRp8uTJuuOOOyRJs2bNUmFhoZYtW6bhw4erbt26SkhIkMViUUZGhu01TWWLDFwxevRozZkzRz///LP69etne5vA/v37FRwcrGnTpmnixIl2Pzts2DB9+OGH+uKLL7Rt2zY1bdpUwcHBateunf761786vW5sbKw+/vhjjRgxQkuXLtWqVatsb04oW0Xavn17vffeey7/Jke+//57zZkzR0FBQWrevLliY2OVm5urI0eOqKSkRHFxcXr11Vfddj0AnkNwA1AlXnnlFdWpU0dfffWV0tLSbNOOI0aMsLWpWbOm5s2bp+XLlys1NVXff/+99u7dq1q1aqlRo0bq2bOn7r77bkNTilFRUVq2bJmmTp2qr7/+WsePH1e9evV077336umnn1bt2rUdfrZTp05KTU3VzJkztWfPHm3durXCSk5nbrvtNm3cuFHvvvuuVq1apQMHDigsLEwdO3bU4MGDNWbMGEVGRrr8mxxJTk7WihUrtHnzZv373//Wrl27FB4erlatWqlfv36aMGFChY15AfimoOzsbNfG+QEAAFAleMYNAADATxDcAAAA/ATBDQAAwE8Q3AAAAPwEwQ0AAMBPENwAAAD8BMENAADATxDcAAAA/ATBDQAAwE8Q3AAAAPwEwQ0AAMBPENwAAAD8BMENAADATxDcAAAA/MT/B/wtX1TUCewuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(training_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
